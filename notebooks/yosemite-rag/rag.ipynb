{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yosemite\n",
    "\n",
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;255;165;0m\u001b[1mYosemite\u001b[0m\u001b[38;2;255;165;0m\u001b[0m\n",
      "\u001b[38;2;128;128;128m\u001b[3mHammad Saeed\u001b[0m\u001b[38;2;128;128;128m\u001b[0m\n",
      "\u001b[38;2;68;68;68m\u001b[3mhttps://code.hammad.fun\u001b[0m\u001b[38;2;68;68;68m\u001b[0m\n",
      "\u001b[38;2;68;68;68m\u001b[3mhttps://github.com/hsaeed3/yosemite\u001b[0m\u001b[38;2;68;68;68m\u001b[0m\n",
      "\u001b[38;2;128;128;128m\u001b[3m0.1.xxx - Half Dome\u001b[0m\u001b[38;2;128;128;128m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Library\n",
    "# ! pip install yosemite --upgrade\n",
    "\n",
    "! yosemite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHello!\u001b[0m\n",
      "\u001b[48;2;200;255;200m\u001b[38;2;0;0;0m\u001b[1mWelcome to One Class RAG!\u001b[0m\u001b[48;2;200;255;200m\u001b[38;2;0;0;0m\u001b[0m\u001b[48;2;200;255;200m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from yosemite import Yosemite\n",
    "\n",
    "# Yosemite Core (Simple Text Styling / Python Utils)\n",
    "yosemite = Yosemite()\n",
    "yosemite.say(\"Hello!\", \"yellow\")\n",
    "yosemite.say(\"Welcome to One Class RAG!\", color=\"rgb(0, 0, 0)\", bg=\"rgb(200, 255, 200)\", bold=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import RAG Module\n",
    "from yosemite.ml import RAG\n",
    "\n",
    "# The RAG Module is Built off several other Modules from this Library\n",
    "\n",
    "# from yosemite.llms import LLM\n",
    "\n",
    "# These classes are built right on top of sentence-transformers, just to make using them a bit easier\n",
    "# from yosemite.ml import CrossEncoder, SentenceTransformer\n",
    "\n",
    "# spaCy\n",
    "# from yosemite.ml.text import Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized with provider: openai\n"
     ]
    }
   ],
   "source": [
    "# Currently the RAG class only supports a handful of API's, but local models\n",
    "# and more API support shall be added indeed.\n",
    "# Universal Huggingface Transformers are my next planned addition\n",
    "    # Current Providers:\n",
    "    # - OpenAI : 'openai'\n",
    "    # - Anthropic Claude : 'anthropic'\n",
    "    # - NVIDIA API : 'nvidia'\n",
    "\n",
    "# Lets choose a provider now\n",
    "provider = \"openai\"\n",
    "api_key = \"\" # Add your Provider's API key.\n",
    "\n",
    "# Initialize the class with a provider\n",
    "rag = RAG(\n",
    "    provider=provider, \n",
    "    api_key=api_key,\n",
    "    # base_url = for NVIDIA models\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating New Database... @ default path = './databases/db'\n"
     ]
    }
   ],
   "source": [
    "# The RAG Class uses a 'Universal Database' using Annoy and Whoosh for both elastic\n",
    "# and Vector Search\n",
    "# from yosemite.ml import Database\n",
    "\n",
    "# Lets Create a blank database now\n",
    "rag.build()\n",
    "\n",
    "# As you can see a /databases/db directory has been generated, this is the default \n",
    "# path the module uses, you may specify your own with:\n",
    "    # rag.build(db=\"<PATH TO YOUR DB || OR || AN EXISTING DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently the Database can load in both lists/strings/tuples of text, or it is able to parse through\n",
    "# Directories and extract -> chunk -> clean -> vectorize CSV's, PDF's and .txt with a comfy schema to use.\n",
    "# The DB itself and all its classes are accessible through the RAG using:\n",
    "    # RAG.db.function()\n",
    "# Using RAG.db also provides quick access to the Whoosh backend, where all it's functions are usable.\n",
    "\n",
    "# Lets add some documents now!\n",
    "# The /documents directory provides 2 movie scripts and a paper on Quiet-STar learning.\n",
    "rag.db.load_docs(\"documents/\")\n",
    "\n",
    "# The Pipeline here is extensive, so it may take a second.\n",
    "# SentenceBERT is used for Embeddings\n",
    "# spaCy is used for chunking/tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our documents are loaded, lets mess with our RAG agent's personality a little\n",
    "# This stage is optional, and is not essential to using this pipeline but it makes it a but cooler\n",
    "rag.customize(\n",
    "    name = \"Lightning McQueen\",\n",
    "    role = \"Racecar\",\n",
    "    tone = \"friendly\",\n",
    "    additional_instructions= \"Answer everything incorporating your signature keywords like 'KACHOW!'\"\n",
    "    # goal = \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mHey there! So, Quiet-STar learning is a process that involves training a model to understand patterns and information from a given dataset. It uses various algorithms to analyze and learn from the data to make predictions or provide insights. In simpler terms, it's all about using mathematical techniques to help computers learn from data and make smart decisions. KACHOW!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Alright, looks like we're all set to go!\n",
    "# Lets send a query to our RAG.\n",
    "\n",
    "# For this test case, the Quiet-STar paper was placed as one of the documents specifically; as it was trained\n",
    "# Incredibly recently (March 14 2024)\n",
    "\n",
    "# Generate a response from the RAG agent and print it.\n",
    "response = rag.invoke(\n",
    "    query = \"What is Quiet-STar learning?\", \n",
    "\n",
    ")\n",
    "\n",
    "# Print Response \n",
    "yosemite.say(response, color=\"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
