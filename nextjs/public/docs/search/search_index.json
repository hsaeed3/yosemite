{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Yosemite","text":""},{"location":"#the-natural-park-of-easy-to-use-python-tools-for-data-science-generative-ai","title":"The Natural Park of easy-to-use Python Tools for Data Science &amp; Generative AI.","text":"<p> |  |  </p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install yosemite\n\nyosemite\n</code></pre>"},{"location":"#quick-references","title":"Quick References","text":"<p>Get Started | Core YosemiteDB | Transformers </p>"},{"location":"#yosemite_1","title":"Yosemite","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Yosemite is my personal open source project, that has been developed constantly since November 2023. It is a collection of Python tools for Data Science and Generative AI, that I have developed for my own use, and uploaded to PyPI for others to use. Yosemite has come in quite a LOT a few shapes and sizes, so just for fun I've attached them all here.</p> Release Date Package 11 / 2023 hammock 12 / 2024 hammad-python 01 / 2024 hammPy 02 / 2024 hammadpy 02 / 2024 hammadml 03 / 2024 Yosemite <p>Currently the package is capable of:</p> <ul> <li>CLI Text Styling, User Inputs, Dialogs, and Progress Loaders.</li> <li>A 'Unified' Elastic &amp; Vector Search Engine &amp; Database, that can be used locally like a function rather than a chunky service.</li> <li>Simpler LLM API Calls (currently supports Anthropic, OpenAI (w/ Instructor), Huggingface &amp; NVIDIA APIs)</li> <li>Simpler Text Transformations (sentence-transformers &amp; spacy)</li> </ul> <p>The next page explains how to get started using Yosemite.</p> <p>Get Started</p>"},{"location":"api/core/","title":"Yosemite Core Tools","text":"<pre><code>from yosemite import Yosemite\n\nYosemite()\n</code></pre>"},{"location":"api/core/#yosemite.main.Yosemite","title":"<code>Yosemite</code>","text":"<p>The core entrypoint for Yosemite tools.</p> Example <pre><code># Import Yosemite\nfrom yosemite import Yosemite\n\n# Initialize Yosemite\ncore = Yosemite()\n\n# Styled Text\ncore.say(\"Hello, Yosemite!\" color=\"blue\", bg=\"white\", bold=True, italic=True, underline=True)\n\n# List\nlist_items = [\"This is a list\", \"With some items\", \"And some colors\"]\ncore.list(list_items, color=\"blue\", bg=\"white\", bold=True)\n\n# ASCII Art\ncore.art(\"yosemite\", art=\"random\", color=\"rgb(255, 0, 0)\")\n\n# Loaders\nwith core.loader(\"Loading...\"):\n    time.sleep(2)\n\n# Inputs\nname = core.input.ask(\"What is your name?\")\n\n# Dialogs\nif core.dialog.confirm(\"Do you want to continue?\"):\n    core.say(f\"Hello, {name}!\")\nelse:\n    core.say(\"Goodbye!\")\n</code></pre> <p>Methods:</p> Name Description <code>art</code> <p>A method to display ASCII art. </p> <code>say</code> <p>A method to display styled text.</p> <code>list</code> <p>A method to display a list of items.</p> <code>loader</code> <p>A class to display loading animations. (Depreciated)</p> <code>timer</code> <p>A context manager to time code execution. </p> <code>inputs</code> <p>A class to handle user inputs.</p> <code>dialog</code> <p>A class to display dialogs.</p> API Reference <p>Art Styles Text Styles Loaders Timer Inputs Dialogs </p> Source code in <code>yosemite/main.py</code> <pre><code>class Yosemite:\n    \"\"\"\n    The core entrypoint for Yosemite tools.\n\n    Example:\n        ```python\n        # Import Yosemite\n        from yosemite import Yosemite\n\n        # Initialize Yosemite\n        core = Yosemite()\n\n        # Styled Text\n        core.say(\"Hello, Yosemite!\" color=\"blue\", bg=\"white\", bold=True, italic=True, underline=True)\n\n        # List\n        list_items = [\"This is a list\", \"With some items\", \"And some colors\"]\n        core.list(list_items, color=\"blue\", bg=\"white\", bold=True)\n\n        # ASCII Art\n        core.art(\"yosemite\", art=\"random\", color=\"rgb(255, 0, 0)\")\n\n        # Loaders\n        with core.loader(\"Loading...\"):\n            time.sleep(2)\n\n        # Inputs\n        name = core.input.ask(\"What is your name?\")\n\n        # Dialogs\n        if core.dialog.confirm(\"Do you want to continue?\"):\n            core.say(f\"Hello, {name}!\")\n        else:\n            core.say(\"Goodbye!\")\n        ```\n\n    Methods:\n        art: A method to display ASCII art. \n        say: A method to display styled text.\n        list: A method to display a list of items.\n        loader: A class to display loading animations. (Depreciated)\n        timer: A context manager to time code execution. \n        inputs: A class to handle user inputs.\n        dialog: A class to display dialogs.\n\n    API Reference:\n        [Art Styles](tools/yosemite.tools.text.md) &lt;br&gt;\n        [Text Styles](tools/yosemite.tools.text.md) &lt;br&gt;\n        [Loaders](tools/yosemite.tools.load.md) &lt;br&gt;\n        [Timer](tools/yosemite.tools.load.md) &lt;br&gt;\n        [Inputs](tools/yosemite.tools.input.md) &lt;br&gt;\n        [Dialogs](tools/yosemite.tools.input.md) &lt;br&gt;\n    \"\"\"\n    def __init__(self):\n\n        # Text Styling\n        text = Text()\n        self.art = text.splash\n        self.say = text.say\n        self.list = text.list\n\n        # Loaders\n        self.loader = Loader\n        self.timer = Timer\n\n        # Inputs\n        self.input = Input()\n\n        # Dialogs\n        self.dialog = Dialog\n\n        pass\n</code></pre>"},{"location":"api/get_started/","title":"Get Started","text":""},{"location":"api/get_started/#install","title":"Install","text":"<p>Yosemite is available on PyPI, as two separate versions, you can install the yosemite-tiny package for extremely lightweight CLI tools only, or the yosemite package for the full suite of tools. All core functions are available in the base yosemite package.</p> <pre><code>pip install yosemite\n\n# Yosemite Core Only\npip install yosemite-tiny\n</code></pre> <p></p> <p>To test the installation, run either of the following commands:</p> <pre><code>yosemite\n\n# or\nyosemite-tiny\n</code></pre>"},{"location":"api/heat/","title":"HEAT","text":""},{"location":"api/heat/#hammads-extreme-artilery-toolkit","title":"Hammad's Extreme Artilery Toolkit","text":"<p>Last November I sat down and scratched my head because I wanted quick colored text in my Python code. Colorama was quick, but I said Sure, I can make it BETTER.. YES.. So I made Yosemite version Beta-\u221e. It's called HEAT, or Hammad's Extreme Artilery Toolkit. So impressed with my work, I took it further; publishing my great script on PyPi.</p> <p>I actually included this as a module, because it doesnt add any extra dependencies to the package, so you can try it if you really want, with:</p> <pre><code>from yosemite.prehistoric.heat import Core\n</code></pre> <p>Here's the entire 'package', because open source and what not. Remember this is ancient, like a vault from November 2023. As you will be able to tell, this is truly an enterprise level product. </p> <pre><code>\"\"\"\nhammock ~ hammad's open code toolkit\n\nv~final out of 10000000 attempts\nhopefully\n\"\"\"\n\n\n\"\"\"\nhammock core now simplified\neverything is now in one script\n\"\"\"\n\n\nimport os\nfrom colorama import Fore, Style\nfrom pathlib import Path\nimport logging\n\n\n\"\"\"\nRadio\n\ncontains message functions for everything now\n\"\"\"\n\nclass Radio:\n\n    @staticmethod\n    def success(message=None, arg=None):\n        print(Fore.GREEN + f'[HKIT ~ SUCCESS] ' + Style.RESET_ALL + f'{Fore.GREEN + Style.BRIGHT}{message} {Fore.WHITE + Style.BRIGHT}{arg}' + Style.RESET_ALL if arg else Fore.GREEN + f'[SUCCESS] ' + Style.RESET_ALL + f'{Fore.GREEN + Style.BRIGHT}{message}' + Style.RESET_ALL)\n\n    @staticmethod\n    def warning(message=None, arg=None):\n        print(Fore.LIGHTMAGENTA_EX + f'[HKIT ~ WARNING] ' + Style.RESET_ALL + f'{Fore.LIGHTMAGENTA_EX + Style.BRIGHT}{message} {Fore.WHITE + Style.BRIGHT}{arg}' + Style.RESET_ALL if arg else Fore.LIGHTMAGENTA_EX + f'[WARNING] ' + Style.RESET_ALL + f'{Fore.LIGHTMAGENTA_EX + Style.BRIGHT}{message}' + Style.RESET_ALL)\n\n    @staticmethod\n    def error(message=None, arg=None, etype=None):\n        print(Fore.RED + f'[HKIT ~ ERROR] ' + Style.RESET_ALL + f'{Fore.RED + Style.BRIGHT}[{etype}] = {message} {Fore.WHITE + Style.BRIGHT}{arg}' + Style.RESET_ALL if arg and etype else Fore.RED + f'[ERROR] ' + Style.RESET_ALL + f'{Fore.RED + Style.BRIGHT}{message}' + Style.RESET_ALL)\n\n    @staticmethod\n    def status(message=None, arg=None):\n        print(Fore.LIGHTYELLOW_EX + f'[HKIT ~ STATUS] ' + Style.RESET_ALL + f'{Fore.YELLOW + Style.DIM}{message} {Fore.WHITE + Style.DIM}{arg}' + Style.RESET_ALL if arg else Fore.LIGHTYELLOW_EX + f'[STATUS] ' + Style.RESET_ALL + f'{Fore.YELLOW + Style.DIM}{message}' + Style.RESET_ALL)\n\n    @staticmethod\n    def info(message=None, arg=None):\n        print(Fore.LIGHTBLACK_EX + f'[HKIT ~ INFO] ' + Style.RESET_ALL + f'{Fore.LIGHTBLACK_EX + Style.BRIGHT}{message} {Fore.WHITE + Style.BRIGHT}{arg}' + Style.RESET_ALL if arg else Fore.LIGHTBLACK_EX + f'[INFO] ' + Style.RESET_ALL + f'{Fore.LIGHTBLACK_EX + Style.BRIGHT}{message}' + Style.RESET_ALL)\n\n\n\"\"\"\nCoreError \n\"\"\"\n\nclass CoreError(Exception):\n    def __init__(self, message=None, arg=None):\n        self.message = message\n\n    def __str__(self):\n        return f'{self.message}'\n\n\"\"\"\nCoreError ~ Types\n\nusage:\n    raise NoArg(arg)\n    raise NoDir(arg)\n    raise NoPath(arg)\n    raise DoesNotExist(arg)\n    raise InvalidDirectory(arg)\n    raise InvalidFile(arg)\n    raise InvalidExtension(arg)\n    raise InvalidArgument(arg)\n\"\"\"\n\nclass NoArg(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'NoArg'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify an argument for ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if there is no directory provided\nclass NoDir(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'NoDir'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a directory for ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if there is no path provided\nclass NoPath(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'NoPath'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a path for ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if the path does not exist\nclass DoesNotExist(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'DoesNotExist'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a real path for ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if the directory is invalid\nclass InvalidDirectory(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'InvalidDirectory'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a valid path for Directory ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if the file is invalid\nclass InvalidFile(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'InvalidFile'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a valid path for File ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if the extension is invalid\nclass InvalidExtension(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'InvalidExtension'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a valid extension for ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\n# Used if the argument is invalid\nclass InvalidArgument(CoreError):\n    def __init__(self, arg = None, message = None):\n        super().__init__(message)\n        self.etype = 'InvalidArgument'\n        self.arg = arg\n        if not self.message:\n            self.message = f'Please Specify a valid argument for ='\n\n    def __str__(self):\n        Radio.error(self.message, self.arg, self.etype)\n\n\"\"\"\nCoreLogger // Now Just Logger\n\"\"\"\n\nclass Logger:\n    def __init__(self, name, log_dir='logs', level=logging.DEBUG):\n        self.logger = logging.getLogger(name)\n        self.logger.setLevel(level)\n\n        if not os.path.exists(log_dir):\n            os.makedirs(log_dir)\n\n        file_handler = logging.FileHandler(os.path.join(log_dir, 'app.log'))\n        file_handler.setLevel(level)\n\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(level)\n\n        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n\n        self.logger.addHandler(file_handler)\n        self.logger.addHandler(console_handler)\n\n    def log(self, level, msg, *args, **kwargs):\n        colored_msg = Fore.LIGHTBLACK_EX + f'{msg} ' + Fore.LIGHTCYAN_EX + f'{args}' + Style.RESET_ALL\n        self.logger.log(level, colored_msg, *args, **kwargs)  \n\n\n\"\"\"\nCoreTools ~ Now also added here\n\"\"\"\n\ndef dir_exist(directory: str = None) -&gt; bool:\n\n    if not directory:\n        raise NoDir(arg='directory', message=None)\n    directory = Path(directory)\n    if not directory.exists():\n        raise DoesNotExist(arg=directory, message=None)\n    if not directory.is_dir():\n        raise InvalidDirectory(arg=directory, message=None)\n    return str(directory)\n\ndef file_exist(path: str = None) -&gt; bool:\n\n    if not path:\n        raise NoPath(arg='path', message=None)\n    path = Path(path)\n    if not path.exists():\n        raise DoesNotExist(arg=path, message=None)\n    if not path.is_file():\n        raise InvalidFile(arg=path, message=None)\n    return str(path)\n\ndef spec_file(path: str = None, ext: str = None) -&gt; bool:\n\n    file_path = file_exist(path)\n    file_path = Path(file_path)\n    if file_path.suffix != ext:\n        raise InvalidExtension(arg=file_path, message=f'Please Verify Your File Ends With [{ext}] @')\n    path = str(file_path)\n    return path\n\n\n\"\"\"\nFinally, Hammock Core\n\"\"\"\n\nclass Core:\n\n    \"\"\"\n    File / Directory Verification\n    \"\"\"\n\n    def dir(directory: str = None) -&gt; bool:\n\n        Radio.status(message='Verifying Directory @', arg=directory)\n        if dir_exist(directory):\n            Radio.success(message='Directory Verified @', arg=directory)\n            return directory\n        else:\n            pass\n\n    def file(path: str = None) -&gt; bool:\n\n        Radio.status(message='Verifying File @', arg=path)\n        if file_exist(path):\n            Radio.success(message='File Verified @', arg=path)\n            return path\n        else:\n            pass\n\n    def ext(path: str = None, ext: str = None) -&gt; bool:\n\n        Radio.status(message='Verifying File Extension @', arg=path)\n        if spec_file(path, ext):\n            Radio.success(message='File Extension Verified @', arg=path)\n            return path\n        else:\n            pass\n\n\nif __name__ == '__main__':\n\n    try:\n        Core.dir(directory='/Users/hammad/Desktop/dev/hamlib/core')\n        Core.file(path='/Users/hammad/Desktop/dev/hamlib/core/nucleus/__init__.py')\n        Core.ext(path='/Users/hammad/Desktop/dev/hamlib/core/nucleus/__init__.py', ext='.py')\n    except Exception as e:\n        raise CoreError(e)\n</code></pre>"},{"location":"api/ml/ml/","title":"Yosemite - ML","text":"<p>The following pages outline using the ML functions provided in Yosemite.</p>"},{"location":"api/ml/yosemite.ml.text/","title":"Text Utilities Using spaCy","text":""},{"location":"api/ml/yosemite.ml.text/#yosemite.ml.text.Chunker","title":"<code>Chunker</code>","text":"<p>A class to chunk text into individual sentences or chunks.</p> Example <pre><code>from yosemite.ml.text import Chunker\nchunker = Chunker()\ntext = \"This is a long text. It consists of multiple sentences. The Chunker class will split it into individual sentences or chunks.\"\nsentences = chunker.chunk_text(text)\nfor sentence in sentences:\n    print(sentence)\n</code></pre> <pre><code>This is a long text.\nIt consists of multiple sentences.\nThe Chunker class will split it into individual sentences or chunks.\n</code></pre> <p>Attributes:</p> Name Type Description <code>nlp</code> <p>A spaCy NLP model to process text.</p> Source code in <code>yosemite/ml/text.py</code> <pre><code>class Chunker:\n    \"\"\"\n    A class to chunk text into individual sentences or chunks.\n\n    Example:\n        ```python\n        from yosemite.ml.text import Chunker\n        chunker = Chunker()\n        text = \"This is a long text. It consists of multiple sentences. The Chunker class will split it into individual sentences or chunks.\"\n        sentences = chunker.chunk_text(text)\n        for sentence in sentences:\n            print(sentence)\n        ```\n\n        ```bash\n        This is a long text.\n        It consists of multiple sentences.\n        The Chunker class will split it into individual sentences or chunks.\n        ```\n\n    Attributes:\n        nlp: A spaCy NLP model to process text.\n    \"\"\"\n\n    def __init__(self, model: str = \"en_core_web_sm\"):\n        ensure_model(model)\n        self.nlp = spacy.load(model)\n\n    def chunk(self, text: Union[str, List[str], Tuple[str], List[Tuple[str]]]) -&gt; List[str]:\n        \"\"\"\n        Chunk text into individual sentences or chunks.\n\n        Example:\n            ```python\n            Chunker.chunk_text(\"This is a long text. It consists of multiple sentences.\")\n            ```\n\n        Args:\n            text: A string, list of strings, tuple of strings, or list of tuples of strings to chunk.\n\n        Returns:\n            A list of strings representing individual sentences or chunks.\n        \"\"\"\n\n        if not text:\n            return []\n\n        if isinstance(text, str):\n            doc = self.nlp(text)\n            if len(doc) &gt; 500: # Adjust the threshold as needed\n                return [chunk.text.strip() for chunk in doc.sents if len(chunk) &gt; 1]\n            else:\n                return [sent.text.strip() for sent in doc.sents]\n        elif isinstance(text, (list, tuple)):\n            if all(isinstance(item, str) for item in text):\n                return [self.chunk_text(item) for item in text]\n            elif all(isinstance(item, (list, tuple)) for item in text):\n                return [self.chunk_text(subitem) for item in text for subitem in item]\n            else:\n                raise ValueError(\"Invalid input type. Expected str, list, tuple, or list of tuples.\")\n</code></pre>"},{"location":"api/ml/yosemite.ml.text/#yosemite.ml.text.Chunker.chunk","title":"<code>chunk(text)</code>","text":"<p>Chunk text into individual sentences or chunks.</p> Example <pre><code>Chunker.chunk_text(\"This is a long text. It consists of multiple sentences.\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>Union[str, List[str], Tuple[str], List[Tuple[str]]]</code> <p>A string, list of strings, tuple of strings, or list of tuples of strings to chunk.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of strings representing individual sentences or chunks.</p> Source code in <code>yosemite/ml/text.py</code> <pre><code>def chunk(self, text: Union[str, List[str], Tuple[str], List[Tuple[str]]]) -&gt; List[str]:\n    \"\"\"\n    Chunk text into individual sentences or chunks.\n\n    Example:\n        ```python\n        Chunker.chunk_text(\"This is a long text. It consists of multiple sentences.\")\n        ```\n\n    Args:\n        text: A string, list of strings, tuple of strings, or list of tuples of strings to chunk.\n\n    Returns:\n        A list of strings representing individual sentences or chunks.\n    \"\"\"\n\n    if not text:\n        return []\n\n    if isinstance(text, str):\n        doc = self.nlp(text)\n        if len(doc) &gt; 500: # Adjust the threshold as needed\n            return [chunk.text.strip() for chunk in doc.sents if len(chunk) &gt; 1]\n        else:\n            return [sent.text.strip() for sent in doc.sents]\n    elif isinstance(text, (list, tuple)):\n        if all(isinstance(item, str) for item in text):\n            return [self.chunk_text(item) for item in text]\n        elif all(isinstance(item, (list, tuple)) for item in text):\n            return [self.chunk_text(subitem) for item in text for subitem in item]\n        else:\n            raise ValueError(\"Invalid input type. Expected str, list, tuple, or list of tuples.\")\n</code></pre>"},{"location":"api/ml/yosemite.ml.transformers/","title":"Text Transformers w/ BERT","text":"<p>This class utilizes <code>sentence-transformers</code> for a few quick and easy text transformations. </p> <pre><code>from yosemite.ml.transformers import \n    CrossEncoder, \n    Loss, \n    SemanticSearch, \n    SentenceSimilarity, \n    SentenceTransformer \n</code></pre> API Reference CrossEncoder Loss SemanticSearch SentenceSimilarity SentenceTransformer"},{"location":"api/ml/data/yosemite.ml.data.database/","title":"Database (Legacy)","text":""},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database","title":"<code>Database</code>","text":"<p>A class for creating simple databases with Whoosh. Old.</p> <pre><code>from yosemite.ml.legacy.database import Database\n</code></pre> <p>Attributes:</p> Name Type Description <code>ix</code> <p>The Whoosh index object.</p> <code>schema</code> <p>The Whoosh schema object.</p> <code>index_dir</code> <p>The directory path to the index.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The directory path to the index.</p> required <code>schema</code> <code>Schema</code> <p>A Whoosh Schema to define the index structure.</p> required <code>analyzer</code> <code>str</code> <p>The type of analyzer to use. Options are \"standard\", \"fancy\", \"language\", and \"keyword\".</p> required <p>Methods:</p> Name Description <code>load</code> <p>Loads an existing index.</p> <code>create</code> <p>Creates a new index.</p> <code>load_dataset</code> <p>Adds documents to an index, by reading a dataset.</p> <code>load_docs</code> <p>Adds documents to an index, by reading text files from a directory.</p> <code>add</code> <p>Adds documents to an index.</p> <code>search</code> <p>Searches the index.</p> Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>class Database:\n    \"\"\"\n    A class for creating simple databases with Whoosh. Old.\n\n    ```python\n    from yosemite.ml.legacy.database import Database\n    ```\n\n    Attributes:\n        ix: The Whoosh index object.\n        schema: The Whoosh schema object.\n        index_dir: The directory path to the index.\n\n    Args:\n        dir (str): The directory path to the index.\n        schema (Schema): A Whoosh Schema to define the index structure.\n        analyzer (str): The type of analyzer to use. Options are \"standard\", \"fancy\", \"language\", and \"keyword\".\n\n    Methods:\n        load: Loads an existing index.\n        create: Creates a new index.\n        load_dataset: Adds documents to an index, by reading a dataset.\n        load_docs: Adds documents to an index, by reading text files from a directory.\n        add: Adds documents to an index.\n        search: Searches the index.\n    \"\"\"\n    def __init__(self):\n        self.ix = None\n        self.schema = None\n        self.index_dir = None\n\n    def load(self, dir: str):\n        \"\"\"\n        Loads an existing index.\n\n        Example:\n            ```python\n            db = Database()\n            db.load(\"./databases/db\")\n            ```\n\n        Args:\n            dir (str): Path to the index directory.\n        \"\"\"\n        self.index_dir = dir\n        if not pl.Path(self.index_dir).exists():\n            return print(f\"Index directory {self.index_dir} does not exist.\")\n        if not whoosh_index.exists_in(self.index_dir):\n            return print(f\"Index does not exist in directory {self.index_dir}.\")\n        self.ix = whoosh_index.open_dir(self.index_dir)\n\n    def create(self, dir: Optional[str] = None, schema: Optional[Schema] = None, analyzer: Optional[str] = \"standard\"):\n        \"\"\"\n        Creates a new index.\n\n        Example:\n            ```python\n            db = Database()\n            db.create()\n            ```\n\n        Args:\n            dir (Optional[str]): Path to the index directory.\n            schema (Optional[Schema]): A Whoosh Schema to define the index structure.\n            analyzer (Optional[str]): The type of analyzer to use. Options are \"standard\", \"fancy\", \"language\", and \"keyword\".\n        \"\"\"\n        if schema is None and analyzer == \"standard\":\n            self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=StandardAnalyzer(), stored=True))\n        elif schema is None and analyzer == \"fancy\":\n            self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=FancyAnalyzer(), stored=True))\n        elif schema is None and analyzer == \"language\":\n            self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=LanguageAnalyzer(), stored=True))\n        elif schema is None and analyzer == \"keyword\":\n            self.schema = Schema(id=ID(stored=True), content=KEYWORD(analyzer=KeywordAnalyzer(), stored=True))\n        else:\n            self.schema = schema\n        if dir is None:\n            self.index_dir = \"./databases/db\"\n            if not pl.Path(self.index_dir).exists():\n                pl.Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n        else:\n            self.index_dir = dir\n            if not pl.Path(self.index_dir).exists():\n                pl.Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n        self.ix = whoosh_index.create_in(self.index_dir, self.schema)\n\n    def load_dataset(self, path: str, id_column: str, content_column: str):\n        \"\"\"\n        Adds documents to an index, by reading a dataset.\n\n        Example:\n            ```python\n            db = Database()\n            db.load_dataset(\"dataset.csv\", \"id\", \"content\")\n            ```\n\n        Args:\n            path (str): The path to the dataset.\n            id_column (str): The name of the column containing the document IDs.\n            content_column (str): The name of the column containing the document content.\n        \"\"\"\n        if not self.ix:\n            self.create()\n        df = pd.read_csv(path)\n        writer = self.ix.writer()\n        for i, row in df.iterrows():\n            writer.add_document(id=row[id_column], content=row[content_column])\n        writer.commit()\n\n    def load_docs(self, dir: str):\n        \"\"\"\n        Adds documents to an index, by reading text files from a directory.\n\n        Args:\n            dir (str): The path to the directory containing the text files.\n\n        Returns:\n            None\n        \"\"\"\n        self.ix = None\n        if not self.ix:\n            self.create(schema=Schema(id=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True)))\n        if not pl.Path(dir).exists():\n            return print(f\"Directory {dir} does not exist.\")\n\n        writer = self.ix.writer()\n        for file_path in pl.Path(dir).glob(\"*\"):\n            if file_path.suffix == \".txt\":\n                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n                    content = file.read()\n                    writer.add_document(id=str(uuid.uuid4()), title=file_path.stem, content=content)\n            elif file_path.suffix == \".pdf\":\n                with open(file_path, \"rb\") as file:\n                    reader = PdfReader(file)\n                    content = \" \".join(page.extract_text() for page in reader.pages)\n                    writer.add_document(id=str(uuid.uuid4()), title=file_path.stem, content=content)\n            elif file_path.suffix == \".epub\":\n                book = epub.read_epub(file_path)\n                content = \" \".join(item.get_content().decode(\"utf-8\") for item in book.get_items_of_type(9))\n                writer.add_document(id=str(uuid.uuid4()), title=book.get_metadata(\"DC\", \"title\")[0][0], content=content)\n        writer.commit()\n\n    def add(self, documents: List[Dict[str, str]], shared_id: Optional[bool] = False):\n        \"\"\"\n        Adds documents to an index.\n\n        Example:\n            ```python\n            db = Database()\n            db.add([{\"content\": \"This is a test document.\"}, {\"content\": \"This is another test document.\"}])\n            ```\n\n        Args:\n            documents (List[Dict[str, str]]): A list of documents to add to the index.\n            shared_id (Optional[bool]): Whether to use a shared ID for all documents.\n        \"\"\"\n        if shared_id:\n            if not self.ix:\n                self.create()\n            writer = self.ix.writer()\n            for doc in documents:\n                writer.add_document(id=\"shared\", content=doc[\"content\"])\n            writer.commit()\n        if not self.ix:\n            self.create()\n        writer = self.ix.writer()\n        for doc in documents:\n            if 'id' not in doc:\n                id = str(uuid.uuid4())\n            else:\n                id = doc['id']\n            writer.add_document(id=id, content=doc[\"content\"])\n        writer.commit()\n\n    def search(self, query: str, fields: Optional[List[str]] = None):\n        \"\"\"\n        Searches the index.\n\n        Example:\n            ```python\n            db = Database()\n            db.create()\n            db.add([{\"content\": \"This is a test document.\"}, {\"content\": \"This is another test document.\"}])\n            results = db.search(\"test\")\n            print(results)\n            ```\n\n        Args:\n            query (str): The query to search for.\n            fields (Optional[List[str]]): A list of fields to search in.\n\n        Returns:\n            List[Dict[str, str]]: A list of search results.\n        \"\"\"\n        if not self.ix:\n            self.create()\n        with self.ix.searcher() as searcher:\n            if fields is None:\n                parser = QueryParser(\"content\", schema=self.schema)\n            else:\n                parser = MultifieldParser(fields, schema=self.schema)\n            try:\n                q = parser.parse(query)\n                results = searcher.search(q)\n                return [{\"id\": hit[\"id\"], \"content\": hit[\"content\"]} for hit in results]\n            except QueryParserError as e:\n                return print(f\"QueryParserError: {e}\")\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database.add","title":"<code>add(documents, shared_id=False)</code>","text":"<p>Adds documents to an index.</p> Example <pre><code>db = Database()\ndb.add([{\"content\": \"This is a test document.\"}, {\"content\": \"This is another test document.\"}])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>List[Dict[str, str]]</code> <p>A list of documents to add to the index.</p> required <code>shared_id</code> <code>Optional[bool]</code> <p>Whether to use a shared ID for all documents.</p> <code>False</code> Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>def add(self, documents: List[Dict[str, str]], shared_id: Optional[bool] = False):\n    \"\"\"\n    Adds documents to an index.\n\n    Example:\n        ```python\n        db = Database()\n        db.add([{\"content\": \"This is a test document.\"}, {\"content\": \"This is another test document.\"}])\n        ```\n\n    Args:\n        documents (List[Dict[str, str]]): A list of documents to add to the index.\n        shared_id (Optional[bool]): Whether to use a shared ID for all documents.\n    \"\"\"\n    if shared_id:\n        if not self.ix:\n            self.create()\n        writer = self.ix.writer()\n        for doc in documents:\n            writer.add_document(id=\"shared\", content=doc[\"content\"])\n        writer.commit()\n    if not self.ix:\n        self.create()\n    writer = self.ix.writer()\n    for doc in documents:\n        if 'id' not in doc:\n            id = str(uuid.uuid4())\n        else:\n            id = doc['id']\n        writer.add_document(id=id, content=doc[\"content\"])\n    writer.commit()\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database.create","title":"<code>create(dir=None, schema=None, analyzer='standard')</code>","text":"<p>Creates a new index.</p> Example <pre><code>db = Database()\ndb.create()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>Optional[str]</code> <p>Path to the index directory.</p> <code>None</code> <code>schema</code> <code>Optional[Schema]</code> <p>A Whoosh Schema to define the index structure.</p> <code>None</code> <code>analyzer</code> <code>Optional[str]</code> <p>The type of analyzer to use. Options are \"standard\", \"fancy\", \"language\", and \"keyword\".</p> <code>'standard'</code> Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>def create(self, dir: Optional[str] = None, schema: Optional[Schema] = None, analyzer: Optional[str] = \"standard\"):\n    \"\"\"\n    Creates a new index.\n\n    Example:\n        ```python\n        db = Database()\n        db.create()\n        ```\n\n    Args:\n        dir (Optional[str]): Path to the index directory.\n        schema (Optional[Schema]): A Whoosh Schema to define the index structure.\n        analyzer (Optional[str]): The type of analyzer to use. Options are \"standard\", \"fancy\", \"language\", and \"keyword\".\n    \"\"\"\n    if schema is None and analyzer == \"standard\":\n        self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=StandardAnalyzer(), stored=True))\n    elif schema is None and analyzer == \"fancy\":\n        self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=FancyAnalyzer(), stored=True))\n    elif schema is None and analyzer == \"language\":\n        self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=LanguageAnalyzer(), stored=True))\n    elif schema is None and analyzer == \"keyword\":\n        self.schema = Schema(id=ID(stored=True), content=KEYWORD(analyzer=KeywordAnalyzer(), stored=True))\n    else:\n        self.schema = schema\n    if dir is None:\n        self.index_dir = \"./databases/db\"\n        if not pl.Path(self.index_dir).exists():\n            pl.Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n    else:\n        self.index_dir = dir\n        if not pl.Path(self.index_dir).exists():\n            pl.Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n    self.ix = whoosh_index.create_in(self.index_dir, self.schema)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database.load","title":"<code>load(dir)</code>","text":"<p>Loads an existing index.</p> Example <pre><code>db = Database()\ndb.load(\"./databases/db\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>Path to the index directory.</p> required Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>def load(self, dir: str):\n    \"\"\"\n    Loads an existing index.\n\n    Example:\n        ```python\n        db = Database()\n        db.load(\"./databases/db\")\n        ```\n\n    Args:\n        dir (str): Path to the index directory.\n    \"\"\"\n    self.index_dir = dir\n    if not pl.Path(self.index_dir).exists():\n        return print(f\"Index directory {self.index_dir} does not exist.\")\n    if not whoosh_index.exists_in(self.index_dir):\n        return print(f\"Index does not exist in directory {self.index_dir}.\")\n    self.ix = whoosh_index.open_dir(self.index_dir)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database.load_dataset","title":"<code>load_dataset(path, id_column, content_column)</code>","text":"<p>Adds documents to an index, by reading a dataset.</p> Example <pre><code>db = Database()\ndb.load_dataset(\"dataset.csv\", \"id\", \"content\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the dataset.</p> required <code>id_column</code> <code>str</code> <p>The name of the column containing the document IDs.</p> required <code>content_column</code> <code>str</code> <p>The name of the column containing the document content.</p> required Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>def load_dataset(self, path: str, id_column: str, content_column: str):\n    \"\"\"\n    Adds documents to an index, by reading a dataset.\n\n    Example:\n        ```python\n        db = Database()\n        db.load_dataset(\"dataset.csv\", \"id\", \"content\")\n        ```\n\n    Args:\n        path (str): The path to the dataset.\n        id_column (str): The name of the column containing the document IDs.\n        content_column (str): The name of the column containing the document content.\n    \"\"\"\n    if not self.ix:\n        self.create()\n    df = pd.read_csv(path)\n    writer = self.ix.writer()\n    for i, row in df.iterrows():\n        writer.add_document(id=row[id_column], content=row[content_column])\n    writer.commit()\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database.load_docs","title":"<code>load_docs(dir)</code>","text":"<p>Adds documents to an index, by reading text files from a directory.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The path to the directory containing the text files.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>def load_docs(self, dir: str):\n    \"\"\"\n    Adds documents to an index, by reading text files from a directory.\n\n    Args:\n        dir (str): The path to the directory containing the text files.\n\n    Returns:\n        None\n    \"\"\"\n    self.ix = None\n    if not self.ix:\n        self.create(schema=Schema(id=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True)))\n    if not pl.Path(dir).exists():\n        return print(f\"Directory {dir} does not exist.\")\n\n    writer = self.ix.writer()\n    for file_path in pl.Path(dir).glob(\"*\"):\n        if file_path.suffix == \".txt\":\n            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n                content = file.read()\n                writer.add_document(id=str(uuid.uuid4()), title=file_path.stem, content=content)\n        elif file_path.suffix == \".pdf\":\n            with open(file_path, \"rb\") as file:\n                reader = PdfReader(file)\n                content = \" \".join(page.extract_text() for page in reader.pages)\n                writer.add_document(id=str(uuid.uuid4()), title=file_path.stem, content=content)\n        elif file_path.suffix == \".epub\":\n            book = epub.read_epub(file_path)\n            content = \" \".join(item.get_content().decode(\"utf-8\") for item in book.get_items_of_type(9))\n            writer.add_document(id=str(uuid.uuid4()), title=book.get_metadata(\"DC\", \"title\")[0][0], content=content)\n    writer.commit()\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.database/#yosemite.ml.legacy.database.Database.search","title":"<code>search(query, fields=None)</code>","text":"<p>Searches the index.</p> Example <pre><code>db = Database()\ndb.create()\ndb.add([{\"content\": \"This is a test document.\"}, {\"content\": \"This is another test document.\"}])\nresults = db.search(\"test\")\nprint(results)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query to search for.</p> required <code>fields</code> <code>Optional[List[str]]</code> <p>A list of fields to search in.</p> <code>None</code> <p>Returns:</p> Type Description <p>List[Dict[str, str]]: A list of search results.</p> Source code in <code>yosemite/ml/legacy/database.py</code> <pre><code>def search(self, query: str, fields: Optional[List[str]] = None):\n    \"\"\"\n    Searches the index.\n\n    Example:\n        ```python\n        db = Database()\n        db.create()\n        db.add([{\"content\": \"This is a test document.\"}, {\"content\": \"This is another test document.\"}])\n        results = db.search(\"test\")\n        print(results)\n        ```\n\n    Args:\n        query (str): The query to search for.\n        fields (Optional[List[str]]): A list of fields to search in.\n\n    Returns:\n        List[Dict[str, str]]: A list of search results.\n    \"\"\"\n    if not self.ix:\n        self.create()\n    with self.ix.searcher() as searcher:\n        if fields is None:\n            parser = QueryParser(\"content\", schema=self.schema)\n        else:\n            parser = MultifieldParser(fields, schema=self.schema)\n        try:\n            q = parser.parse(query)\n            results = searcher.search(q)\n            return [{\"id\": hit[\"id\"], \"content\": hit[\"content\"]} for hit in results]\n        except QueryParserError as e:\n            return print(f\"QueryParserError: {e}\")\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.vector_database/","title":"Vector Database (Legacy)","text":""},{"location":"api/ml/data/yosemite.ml.data.vector_database/#yosemite.ml.legacy.vector_database.VectorDatabase","title":"<code>VectorDatabase</code>","text":"<p>A class representing a vector database.</p> <pre><code>from yosemite.ml.legacy.vector_database import VectorDatabase\n\n# Create a VectorDatabase from a list of strings\ndocuments = [\n    \"Paris is the capital of France.\",\n    \"London is the capital of the United Kingdom.\",\n    \"Berlin is the capital of Germany.\"\n]\nvdb = VectorDatabase()\nvdb.create(documents)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dimension</code> <code>int</code> <p>The dimension of the vectors. Defaults to None.</p> <code>None</code> <code>model_name</code> <code>str</code> <p>The name of the SentenceTransformer model to be used. Defaults to \"all-MiniLM-L6-v2\".</p> <code>'all-MiniLM-L6-v2'</code> <p>Attributes:</p> Name Type Description <code>index</code> <code>AnnoyIndex</code> <p>The Annoy index used for vector search.</p> <code>dimension</code> <code>int</code> <p>The dimension of the vectors.</p> <code>document_ids</code> <code>List[str]</code> <p>The list of document IDs.</p> <code>sentences</code> <code>List[str]</code> <p>The list of sentences.</p> <code>vectors</code> <code>List[List[float]]</code> <p>The list of vectors.</p> <code>model_name</code> <code>str</code> <p>The name of the SentenceTransformer model.</p> <p>Methods:</p> Name Description <code>load</code> <p>str) -&gt; None: Load an existing Annoy index.</p> <code>create</code> <p>Union[str, List[str], List[Tuple[str, list]]], num_trees: int = 10) -&gt; None: Create a new Annoy index.</p> <code>_load_data_from_directory</code> <p>str) -&gt; None: Load data from a directory.</p> <code>_load_data_from_strings</code> <p>List[str]) -&gt; None: Load data from a list of strings.</p> <code>_load_data_from_tuples</code> <p>List[Tuple[str, list]]) -&gt; None: Load data from a list of tuples.</p> <code>_build_index</code> <p>int) -&gt; None: Build the Annoy index.</p> <code>create_from_database</code> <p>str, num_trees: int = 10) -&gt; None: Create a vector database from an existing database.</p> <code>search</code> <p>str, k: int = 5) -&gt; List[Tuple[int, str, str, List[float]]]: Search the vector database.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the index file is not found.</p> <code>ValueError</code> <p>If the input_data is invalid.</p> Source code in <code>yosemite/ml/legacy/vector_database.py</code> <pre><code>class VectorDatabase:\n    \"\"\"\n    A class representing a vector database.\n\n    ```python\n    from yosemite.ml.legacy.vector_database import VectorDatabase\n\n    # Create a VectorDatabase from a list of strings\n    documents = [\n        \"Paris is the capital of France.\",\n        \"London is the capital of the United Kingdom.\",\n        \"Berlin is the capital of Germany.\"\n    ]\n    vdb = VectorDatabase()\n    vdb.create(documents)\n    ```\n\n    Args:\n        dimension (int, optional): The dimension of the vectors. Defaults to None.\n        model_name (str, optional): The name of the SentenceTransformer model to be used. Defaults to \"all-MiniLM-L6-v2\".\n\n    Attributes:\n        index (AnnoyIndex): The Annoy index used for vector search.\n        dimension (int): The dimension of the vectors.\n        document_ids (List[str]): The list of document IDs.\n        sentences (List[str]): The list of sentences.\n        vectors (List[List[float]]): The list of vectors.\n        model_name (str): The name of the SentenceTransformer model.\n\n    Methods:\n        load(index_path: str) -&gt; None: Load an existing Annoy index.\n        create(input_data: Union[str, List[str], List[Tuple[str, list]]], num_trees: int = 10) -&gt; None: Create a new Annoy index.\n        _load_data_from_directory(directory: str) -&gt; None: Load data from a directory.\n        _load_data_from_strings(strings: List[str]) -&gt; None: Load data from a list of strings.\n        _load_data_from_tuples(tuples: List[Tuple[str, list]]) -&gt; None: Load data from a list of tuples.\n        _build_index(num_trees: int) -&gt; None: Build the Annoy index.\n        create_from_database(db_path: str, num_trees: int = 10) -&gt; None: Create a vector database from an existing database.\n        search(query: str, k: int = 5) -&gt; List[Tuple[int, str, str, List[float]]]: Search the vector database.\n\n    Raises:\n        FileNotFoundError: If the index file is not found.\n        ValueError: If the input_data is invalid.\n\n    \"\"\"\n\n    def __init__(self, dimension: Optional[int] = None, model_name: str = \"all-MiniLM-L6-v2\"):\n        self.index = None\n        self.dimension = dimension\n        self.document_ids = []\n        self.sentences = []\n        self.vectors = []\n        self.model_name = model_name\n\n    def load(self, index_path: str) -&gt; None:\n        \"\"\"\n        Load an existing Annoy index.\n\n        Example:\n            ```python\n            vdb = VectorDatabase()\n            vdb.load(\"index.ann\")\n            ```\n\n        Args:\n            index_path (str): The path to the index file.\n\n        Raises:\n            FileNotFoundError: If the index file is not found.\n        \"\"\"\n        if not os.path.isfile(index_path):\n            raise FileNotFoundError(f\"Index file not found: {index_path}\")\n\n        self.index = AnnoyIndex(self.dimension, 'angular')\n        self.index.load(index_path)\n\n    def create(self, input_data: Union[str, List[str], List[Tuple[str, list]]], num_trees: int = 10) -&gt; None:\n        \"\"\"\n        Create a new Annoy index.\n\n        Example:\n            ```python\n            vdb = VectorDatabase()\n            vdb.create([\"Paris is the capital of France.\", \"London is the capital of the United Kingdom.\"])\n            ```\n\n        Args:\n            input_data (Union[str, List[str], List[Tuple[str, list]]]): The input data to create the index from.\n            num_trees (int, optional): The number of trees to build the index. Defaults to 10.\n\n        Raises:\n            ValueError: If the input_data is invalid.\n        \"\"\"\n        if isinstance(input_data, str):\n            if os.path.isdir(input_data):\n                self._load_data_from_directory(input_data)\n            else:\n                raise ValueError(\"Invalid input_data. Expected a directory path.\")\n        elif isinstance(input_data, list):\n            if all(isinstance(item, str) for item in input_data):\n                self._load_data_from_strings(input_data)\n            elif all(isinstance(item, tuple) and len(item) == 2 for item in input_data):\n                self._load_data_from_tuples(input_data)\n            else:\n                raise ValueError(\"Invalid input_data. Expected a list of strings or a list of tuples.\")\n        else:\n            raise ValueError(\"Invalid input_data. Expected a directory path, a list of strings, or a list of tuples.\")\n\n        self._build_index(num_trees)\n\n    def _load_data_from_directory(self, directory: str) -&gt; None:\n        chunker = Chunker()\n        for file_name in os.listdir(directory):\n            if file_name.endswith(\".txt\"):\n                file_path = os.path.join(directory, file_name)\n                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n                    content = file.read().strip()\n                    self.sentences.extend(chunker.chunk_text(content))\n                    self.document_ids.extend([str(uuid.uuid4()) for _ in chunker.chunk_text(content)])\n\n    def _load_data_from_strings(self, strings: List[str]) -&gt; None:\n        chunker = Chunker()\n        self.sentences = [sentence for text in strings for sentence in chunker.chunk_text(text)]\n        self.document_ids = [str(uuid.uuid4()) for _ in self.sentences]\n\n    def _load_data_from_tuples(self, tuples: List[Tuple[str, list]]) -&gt; None:\n        self.sentences, self.vectors = zip(*tuples)\n        self.document_ids = [str(uuid.uuid4()) for _ in tuples]\n\n    def _build_index(self, num_trees: int) -&gt; None:\n        if not self.dimension:\n            self.dimension = len(self.vectors[0]) if self.vectors else SentenceTransformer(self.model_name).model.get_sentence_embedding_dimension()\n\n        self.index = AnnoyIndex(self.dimension, 'angular')\n\n        if self.vectors:\n            for i, vector in enumerate(self.vectors):\n                self.index.add_item(i, vector)\n        else:\n            embedder = SentenceTransformer(self.model_name)\n            for i, sentence in enumerate(self.sentences):\n                vector = embedder.embed([sentence])[0][1]\n                self.index.add_item(i, vector)\n\n        self.index.build(num_trees)\n\n    def create_from_database(self, db_path: str, num_trees: int = 10) -&gt; None:\n        \"\"\"\n        Create a vector database from an existing database.\n\n        Example:\n            ```python\n            vdb = VectorDatabase()\n            vdb.create_from_database(\"database.db\")\n            ```\n\n        Args:\n            db_path (str): The path to the existing database.\n            num_trees (int, optional): The number of trees to build the index. Defaults to 10.\n        \"\"\"\n        self.db = Database()\n        self.db.load(db_path)\n        chunker = Chunker()\n        embedder = SentenceTransformer(self.model_name)\n\n        for doc in self.db.ix.searcher().documents():\n            doc_id = doc[\"id\"]\n            doc_content = doc[\"content\"]\n\n            chunks = chunker.chunk_text(doc_content)\n            for chunk in chunks:\n                self.sentences.append(chunk)\n                self.document_ids.append(doc_id)\n\n                vector = embedder.embed([chunk])[0][1]\n                self.vectors.append(vector)\n\n        self._build_index(num_trees)\n\n    def search(self, query: str, k: int = 5) -&gt; List[Tuple[int, str, str, List[float]]]:\n        \"\"\"\n        Search the vector database.\n\n        Example:\n            ```python\n            vdb = VectorDatabase()\n            vdb.load(\"index.ann\")\n            results = vdb.search(\"What is the capital of France?\")\n            print(results)\n            ```\n\n        Args:\n            query (str): The search query.\n            k (int, optional): The number of results to return. Defaults to 5.\n\n        Returns:\n            List[Tuple[int, str, str, List[float]]]: A list of tuples containing the index, sentence, document ID, and vector.\n        \"\"\"\n        if not self.index:\n            raise ValueError(\"Index has not been built or loaded.\")\n\n        embedder = SentenceTransformer(self.model_name)\n        query_vector = embedder.embed([query])[0][1]\n        indices = self.index.get_nns_by_vector(query_vector, k, include_distances=False)\n        results = []\n        for index in indices:\n            sentence = self.sentences[index]\n            document_id = self.document_ids[index]\n            vector = self.index.get_item_vector(index)\n            results.append((index, sentence, document_id, vector))\n        return results\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.vector_database/#yosemite.ml.legacy.vector_database.VectorDatabase.create","title":"<code>create(input_data, num_trees=10)</code>","text":"<p>Create a new Annoy index.</p> Example <pre><code>vdb = VectorDatabase()\nvdb.create([\"Paris is the capital of France.\", \"London is the capital of the United Kingdom.\"])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[str, List[str], List[Tuple[str, list]]]</code> <p>The input data to create the index from.</p> required <code>num_trees</code> <code>int</code> <p>The number of trees to build the index. Defaults to 10.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input_data is invalid.</p> Source code in <code>yosemite/ml/legacy/vector_database.py</code> <pre><code>def create(self, input_data: Union[str, List[str], List[Tuple[str, list]]], num_trees: int = 10) -&gt; None:\n    \"\"\"\n    Create a new Annoy index.\n\n    Example:\n        ```python\n        vdb = VectorDatabase()\n        vdb.create([\"Paris is the capital of France.\", \"London is the capital of the United Kingdom.\"])\n        ```\n\n    Args:\n        input_data (Union[str, List[str], List[Tuple[str, list]]]): The input data to create the index from.\n        num_trees (int, optional): The number of trees to build the index. Defaults to 10.\n\n    Raises:\n        ValueError: If the input_data is invalid.\n    \"\"\"\n    if isinstance(input_data, str):\n        if os.path.isdir(input_data):\n            self._load_data_from_directory(input_data)\n        else:\n            raise ValueError(\"Invalid input_data. Expected a directory path.\")\n    elif isinstance(input_data, list):\n        if all(isinstance(item, str) for item in input_data):\n            self._load_data_from_strings(input_data)\n        elif all(isinstance(item, tuple) and len(item) == 2 for item in input_data):\n            self._load_data_from_tuples(input_data)\n        else:\n            raise ValueError(\"Invalid input_data. Expected a list of strings or a list of tuples.\")\n    else:\n        raise ValueError(\"Invalid input_data. Expected a directory path, a list of strings, or a list of tuples.\")\n\n    self._build_index(num_trees)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.vector_database/#yosemite.ml.legacy.vector_database.VectorDatabase.create_from_database","title":"<code>create_from_database(db_path, num_trees=10)</code>","text":"<p>Create a vector database from an existing database.</p> Example <pre><code>vdb = VectorDatabase()\nvdb.create_from_database(\"database.db\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the existing database.</p> required <code>num_trees</code> <code>int</code> <p>The number of trees to build the index. Defaults to 10.</p> <code>10</code> Source code in <code>yosemite/ml/legacy/vector_database.py</code> <pre><code>def create_from_database(self, db_path: str, num_trees: int = 10) -&gt; None:\n    \"\"\"\n    Create a vector database from an existing database.\n\n    Example:\n        ```python\n        vdb = VectorDatabase()\n        vdb.create_from_database(\"database.db\")\n        ```\n\n    Args:\n        db_path (str): The path to the existing database.\n        num_trees (int, optional): The number of trees to build the index. Defaults to 10.\n    \"\"\"\n    self.db = Database()\n    self.db.load(db_path)\n    chunker = Chunker()\n    embedder = SentenceTransformer(self.model_name)\n\n    for doc in self.db.ix.searcher().documents():\n        doc_id = doc[\"id\"]\n        doc_content = doc[\"content\"]\n\n        chunks = chunker.chunk_text(doc_content)\n        for chunk in chunks:\n            self.sentences.append(chunk)\n            self.document_ids.append(doc_id)\n\n            vector = embedder.embed([chunk])[0][1]\n            self.vectors.append(vector)\n\n    self._build_index(num_trees)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.vector_database/#yosemite.ml.legacy.vector_database.VectorDatabase.load","title":"<code>load(index_path)</code>","text":"<p>Load an existing Annoy index.</p> Example <pre><code>vdb = VectorDatabase()\nvdb.load(\"index.ann\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>index_path</code> <code>str</code> <p>The path to the index file.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the index file is not found.</p> Source code in <code>yosemite/ml/legacy/vector_database.py</code> <pre><code>def load(self, index_path: str) -&gt; None:\n    \"\"\"\n    Load an existing Annoy index.\n\n    Example:\n        ```python\n        vdb = VectorDatabase()\n        vdb.load(\"index.ann\")\n        ```\n\n    Args:\n        index_path (str): The path to the index file.\n\n    Raises:\n        FileNotFoundError: If the index file is not found.\n    \"\"\"\n    if not os.path.isfile(index_path):\n        raise FileNotFoundError(f\"Index file not found: {index_path}\")\n\n    self.index = AnnoyIndex(self.dimension, 'angular')\n    self.index.load(index_path)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.vector_database/#yosemite.ml.legacy.vector_database.VectorDatabase.search","title":"<code>search(query, k=5)</code>","text":"<p>Search the vector database.</p> Example <pre><code>vdb = VectorDatabase()\nvdb.load(\"index.ann\")\nresults = vdb.search(\"What is the capital of France?\")\nprint(results)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query.</p> required <code>k</code> <code>int</code> <p>The number of results to return. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Tuple[int, str, str, List[float]]]</code> <p>List[Tuple[int, str, str, List[float]]]: A list of tuples containing the index, sentence, document ID, and vector.</p> Source code in <code>yosemite/ml/legacy/vector_database.py</code> <pre><code>def search(self, query: str, k: int = 5) -&gt; List[Tuple[int, str, str, List[float]]]:\n    \"\"\"\n    Search the vector database.\n\n    Example:\n        ```python\n        vdb = VectorDatabase()\n        vdb.load(\"index.ann\")\n        results = vdb.search(\"What is the capital of France?\")\n        print(results)\n        ```\n\n    Args:\n        query (str): The search query.\n        k (int, optional): The number of results to return. Defaults to 5.\n\n    Returns:\n        List[Tuple[int, str, str, List[float]]]: A list of tuples containing the index, sentence, document ID, and vector.\n    \"\"\"\n    if not self.index:\n        raise ValueError(\"Index has not been built or loaded.\")\n\n    embedder = SentenceTransformer(self.model_name)\n    query_vector = embedder.embed([query])[0][1]\n    indices = self.index.get_nns_by_vector(query_vector, k, include_distances=False)\n    results = []\n    for index in indices:\n        sentence = self.sentences[index]\n        document_id = self.document_ids[index]\n        vector = self.index.get_item_vector(index)\n        results.append((index, sentence, document_id, vector))\n    return results\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/","title":"YosemiteDatabase (Unified 'Elastic' and Vector Searchable DB)","text":""},{"location":"api/ml/data/yosemite.ml.data.yosemite/#quick-start","title":"Quick Start","text":"<pre><code>from yosemite.ml.database import YosemiteDatabase\n\n# Initialize the database, Create Empty Database\ndb = YosemiteDatabase()\ndb.create()\n\n# Add Documents\ndocuments = [\n    {\"content\": \"This is a test document.\"},\n    {\"content\": \"This is another test document.\"}\n]\n\n# Add Documents to Database\ndb.add(documents)\n\n# Search for Documents, uses Whoosh text search &amp; Annoy vector search; \n# both ran through a cross encoder and reranked.\nresults = db.search(\"test\")\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase","title":"<code>YosemiteDatabase</code>","text":"<p>A Unified &amp; Local Database with no backend services required. Built using Whoosh &amp; Annoy. Combines the power of Whoosh for text search and Annoy for vector search, to deliver incredibly easy to use and powerful search capabilities.</p> <pre><code>from yosemite.ml.database import YosemiteDatabase\n</code></pre> <p>Attributes:</p> Name Type Description <code>dimension</code> <code>int</code> <p>The dimension of the vectors.</p> <code>model_name</code> <code>str</code> <p>The name of the SentenceTransformer model to be used.</p> <code>schema</code> <code>Schema</code> <p>The schema to be used for the Whoosh index.</p> <code>index_dir</code> <code>str</code> <p>The directory where the Whoosh index is stored.</p> <code>analyzer</code> <code>str</code> <p>The type of analyzer to be used for the Whoosh index.</p> <p>Parameters:</p> Name Type Description Default <code>dimension</code> <code>int</code> <p>The dimension of the vectors. Defaults to None.</p> <code>None</code> <code>model_name</code> <code>str</code> <p>The name of the SentenceTransformer model to be used. Defaults to \"all-MiniLM-L6-v2\".</p> <code>'all-MiniLM-L6-v2'</code> <code>schema</code> <code>Schema</code> <p>The schema to be used for the Whoosh index. Defaults to None.</p> <code>None</code> <code>analyzer</code> <code>str</code> <p>The type of analyzer to be used for the Whoosh index. Defaults to \"standard\".</p> <code>'standard'</code> <p>Methods:</p> Name Description <code>load</code> <p>Load an existing Whoosh index.</p> <code>create</code> <p>Create a new Whoosh index.</p> <code>load_dataset</code> <p>Load a dataset into the Whoosh index.</p> <code>load_docs</code> <p>Load documents from a directory into the Whoosh index.</p> <code>add</code> <p>Add documents to the Whoosh index.</p> <code>search</code> <p>Search the Whoosh index.</p> <code>search_and_rank</code> <p>Search and rank the Whoosh index.</p> Source code in <code>yosemite/ml/database.py</code> <pre><code>class YosemiteDatabase:\n    \"\"\"\n    A Unified &amp; Local Database with no backend services required. Built using Whoosh &amp; Annoy. Combines the power of Whoosh for text search and Annoy for vector search, to deliver incredibly easy to use and powerful search capabilities.\n\n    ```python\n    from yosemite.ml.database import YosemiteDatabase\n    ```\n\n    Attributes:\n        dimension (int): The dimension of the vectors.\n        model_name (str): The name of the SentenceTransformer model to be used.\n        schema (Schema): The schema to be used for the Whoosh index.\n        index_dir (str): The directory where the Whoosh index is stored.\n        analyzer (str): The type of analyzer to be used for the Whoosh index.\n\n    Args:\n        dimension (int, optional): The dimension of the vectors. Defaults to None.\n        model_name (str, optional): The name of the SentenceTransformer model to be used. Defaults to \"all-MiniLM-L6-v2\".\n        schema (Schema, optional): The schema to be used for the Whoosh index. Defaults to None.\n        analyzer (str, optional): The type of analyzer to be used for the Whoosh index. Defaults to \"standard\".\n\n    Methods:\n        load: Load an existing Whoosh index.\n        create: Create a new Whoosh index.\n        load_dataset: Load a dataset into the Whoosh index.\n        load_docs: Load documents from a directory into the Whoosh index.\n        add: Add documents to the Whoosh index.\n        search: Search the Whoosh index.\n        search_and_rank: Search and rank the Whoosh index.\n    \"\"\"\n    def __init__(self, dimension: Optional[int] = None, model_name: str = \"all-MiniLM-L6-v2\", \n                 schema: Optional[Schema] = None, analyzer: Optional[str] = \"standard\"):\n        self.index = None\n        self.dimension = dimension\n        self.model_name = model_name\n        self.ix = None\n        self.schema = schema\n        self.index_dir = None\n        self.analyzer = analyzer\n\n    def load(self, dir: str):\n        \"\"\"\n        A method to load an existing Whoosh index.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.load(\"./databases/db\")\n            ```\n\n        Args:\n            dir (str): The directory where the Whoosh index is stored.\n        \"\"\"\n        self.index_dir = dir\n        if not os.path.exists(self.index_dir):\n            raise FileNotFoundError(f\"Index directory {self.index_dir} does not exist.\")\n        if not whoosh_index.exists_in(self.index_dir):\n            raise FileNotFoundError(f\"Index does not exist in directory {self.index_dir}.\")\n        self.ix = whoosh_index.open_dir(self.index_dir)\n\n    def create(self, dir: Optional[str] = None):\n        \"\"\"\n        A method to create a new Whoosh index.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.create()\n            ```\n\n        Args:\n            dir (str, optional): The directory where the Whoosh index will be stored. Defaults to None.\n        \"\"\"\n        if self.schema is None:\n            if self.analyzer == \"standard\":\n                self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=StandardAnalyzer(), stored=True), \n                                     chunks=TEXT(stored=True), vectors=STORED)\n            elif self.analyzer == \"fancy\":\n                self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=FancyAnalyzer(), stored=True), \n                                     chunks=TEXT(stored=True), vectors=STORED)\n            elif self.analyzer == \"language\":\n                self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=LanguageAnalyzer(), stored=True), \n                                     chunks=TEXT(stored=True), vectors=STORED)\n            elif self.analyzer == \"keyword\":\n                self.schema = Schema(id=ID(stored=True), content=KEYWORD(analyzer=KeywordAnalyzer(), stored=True), \n                                     chunks=TEXT(stored=True), vectors=STORED)\n\n        if dir is None:\n            self.index_dir = \"./databases/db\"\n        else:\n            self.index_dir = dir\n        os.makedirs(self.index_dir, exist_ok=True)\n        self.ix = whoosh_index.create_in(self.index_dir, self.schema)\n\n    def load_dataset(self, path: str, id_column: str, content_column: str):\n        \"\"\"\n        A method to load a CSV dataset into the Whoosh index.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.create()\n            db.load_dataset(\"data.csv\", \"id\", \"content\")\n            ```\n\n        Args:\n            path (str): The path to the CSV dataset.\n            id_column (str): The name of the column containing the document IDs.\n            content_column (str): The name of the column containing the document content.\n        \"\"\"\n        if not self.ix:\n            self.create()\n        df = pd.read_csv(path)\n        writer = self.ix.writer()\n        chunker = Chunker()\n        embedder = SentenceTransformer(self.model_name)\n        for _, row in df.iterrows():\n            doc_id = str(row[id_column])\n            doc_content = row[content_column]\n            chunks = chunker.chunk_text(doc_content)\n            vectors = [embedder.embed([chunk])[0][1] for chunk in chunks]\n            writer.add_document(id=doc_id, content=doc_content, chunks=\"\\n\".join(chunks), vectors=vectors)\n        writer.commit()\n\n    def load_docs(self, dir: str):\n        \"\"\"\n        A very powerful method to load documents from a directory into the Whoosh index. Supports .txt, .pdf, and .epub files.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.create()\n            db.load_docs(\"documents\")\n            ```\n\n        Args:\n            dir (str): The directory containing the documents.\n        \"\"\"\n        if not self.ix:\n            self.create()\n        if not os.path.exists(dir):\n            raise FileNotFoundError(f\"Directory {dir} does not exist.\")\n\n        writer = self.ix.writer()\n        chunker = Chunker()\n        embedder = SentenceTransformer(self.model_name)\n        for file_path in os.listdir(dir):\n            file_path = os.path.join(dir, file_path)\n            if file_path.endswith(\".txt\"):\n                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n                    content = file.read()\n            elif file_path.endswith(\".pdf\"):\n                with open(file_path, \"rb\") as file:\n                    reader = PdfReader(file)\n                    content = \" \".join(page.extract_text() for page in reader.pages)\n            elif file_path.endswith(\".epub\"):\n                book = epub.read_epub(file_path)\n                content = \" \".join(item.get_content().decode(\"utf-8\") for item in book.get_items_of_type(9))\n            else:\n                continue\n\n            doc_id = str(uuid.uuid4())\n            chunks = chunker.chunk_text(content)\n            vectors = [embedder.embed([chunk])[0][1] for chunk in chunks]\n            writer.add_document(id=doc_id, content=content, chunks=\"\\n\".join(chunks), vectors=vectors)\n        writer.commit()\n\n    def add(self, documents: List[Dict[str, str]], shared_id: Optional[bool] = False):\n        \"\"\"\n        A method to add documents to the Whoosh index.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.create()\n            documents = [\n                {\"content\": \"This is a test document.\"},\n                {\"content\": \"This is another test document.\"}\n            ]\n            db.add(documents)\n            ```\n\n        Args:\n            documents (List[Dict[str, str]]): A list of dictionaries containing the document content.\n            shared_id (Optional[bool], optional): Whether to use a shared ID for all documents. Defaults to False.\n        \"\"\"\n        if not self.ix:\n            self.create()\n        writer = self.ix.writer()\n        chunker = Chunker()\n        embedder = SentenceTransformer(self.model_name)\n        for doc in documents:\n            if shared_id:\n                doc_id = \"shared\"\n            else:\n                doc_id = doc.get(\"id\", str(uuid.uuid4()))\n            doc_content = doc[\"content\"]\n            chunks = chunker.chunk_text(doc_content)\n            vectors = [embedder.embed([chunk])[0][1] for chunk in chunks]\n            writer.add_document(id=doc_id, content=doc_content, chunks=\"\\n\".join(chunks), vectors=vectors)\n        writer.commit()\n\n    def search(self, query: str, fields: Optional[List[str]] = None, k: int = 5) -&gt; List[Tuple[str, str, List[float]]]:\n        \"\"\"\n        A method to search the Whoosh &amp; Annoy index.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.load(\"./databases/db\")\n            results = db.search(\"test\")\n            for doc_id, chunk, vector in results:\n                print(f\"Document ID: {doc_id}\")\n                print(f\"Chunk: {chunk}\")\n                print(f\"Vector: {vector}\")\n                print(\"---\")\n            ```\n\n            ```bash\n            Document ID: 1\n            Chunk: This is a test document.\n            Vector: [0.1, 0.2, 0.3, ...]\n            ---\n            Document ID: 2\n            Chunk: This is another test document.\n            Vector: [0.4, 0.5, 0.6, ...]\n            ---\n            ```\n\n        Args:\n            query (str): The search query.\n            fields (Optional[List[str]], optional): The fields to search in. Defaults to None.\n            k (int, optional): The number of results to return. Defaults to 5.\n\n        Returns:\n            List[Tuple[str, str, List[float]]]: A list of tuples containing the document ID, chunk, and vector.\n        \"\"\"\n        if not self.ix:\n            raise ValueError(\"Index has not been built or loaded.\")\n\n        with self.ix.searcher() as searcher:\n            if fields is None:\n                parser = QueryParser(\"content\", schema=self.schema)\n            else:\n                parser = MultifieldParser(fields, schema=self.schema)\n            try:\n                q = parser.parse(query)\n                results = searcher.search(q, limit=k)\n                embedder = SentenceTransformer(self.model_name)\n                query_vector = embedder.embed([query])[0][1]\n                ranked_results = []\n                for hit in results:\n                    doc_id = hit[\"id\"]\n                    doc_content = hit[\"content\"]\n                    doc_vectors = hit[\"vectors\"]\n                    if not self.dimension:\n                        self.dimension = len(doc_vectors[0])\n                    index = AnnoyIndex(self.dimension, 'angular')\n                    for i, vector in enumerate(doc_vectors):\n                        index.add_item(i, vector)\n                    index.build(10)\n                    indices = index.get_nns_by_vector(query_vector, k, include_distances=False)\n                    for idx in indices:\n                        chunk = hit[\"chunks\"].split(\"\\n\")[idx]\n                        ranked_results.append((doc_id, chunk, doc_vectors[idx]))\n                return ranked_results\n            except QueryParserError as e:\n                print(f\"QueryParserError: {e}\")\n                return []\n\n    def search_and_rank(self, query: str, k: int = 5) -&gt; List[Tuple[str, str, float]]:\n        \"\"\"\n        A method to search and rank the Whoosh &amp; Annoy index.\n\n        Example:\n            ```python\n            db = YosemiteDatabase()\n            db.load(\"./databases/db\")\n            results = db.search_and_rank(\"test\")\n            for doc_id, chunk, score in results:\n                print(f\"Document ID: {doc_id}\")\n                print(f\"Chunk: {chunk}\")\n                print(f\"Score: {score}\")\n                print(\"---\")\n            ```\n\n            ```bash\n            Document ID: 1\n            Chunk: This is a test document.\n            Score: 0.9\n            ---\n            Document ID: 2\n            Chunk: This is another test document.\n            Score: 0.8\n            ---\n            ```\n\n        Args:\n            query (str): The search query.\n            k (int, optional): The number of results to return. Defaults to 5.\n\n        Returns:\n            List[Tuple[str, str, float]]: A list of tuples containing the document ID, chunk, and score.\n        \"\"\"\n        if not self.ix:\n            raise ValueError(\"Index has not been built or loaded.\")\n        with self.ix.searcher() as searcher:\n            parser = QueryParser(\"content\", schema=self.schema)\n            try:\n                q = parser.parse(query)\n                whoosh_results = searcher.search(q, limit=k)\n                whoosh_chunks = [hit[\"chunks\"] for hit in whoosh_results]\n            except QueryParserError as e:\n                print(f\"QueryParserError: {e}\")\n                whoosh_chunks = []\n        embedder = SentenceTransformer(self.model_name)\n        query_vector = embedder.embed([query])[0][1]\n        vector_results = []\n        for doc_id, doc_chunks, doc_vectors in zip(self.document_ids, self.sentences, self.vectors):\n            if not self.dimension:\n                self.dimension = len(doc_vectors[0])\n            index = AnnoyIndex(self.dimension, 'angular')\n            for i, vector in enumerate(doc_vectors):\n                index.add_item(i, vector)\n            index.build(10)\n            indices = index.get_nns_by_vector(query_vector, k, include_distances=False)\n            for idx in indices:\n                vector_results.append((doc_id, doc_chunks[idx]))\n\n        combined_results = whoosh_chunks + [chunk for _, chunk in vector_results]\n        cross_encode = CrossEncode()\n        ranked_results = cross_encode.rank(query, combined_results, [])\n        return [(doc_id, chunk, score) for (doc_id, chunk), score in ranked_results]\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.add","title":"<code>add(documents, shared_id=False)</code>","text":"<p>A method to add documents to the Whoosh index.</p> Example <pre><code>db = YosemiteDatabase()\ndb.create()\ndocuments = [\n    {\"content\": \"This is a test document.\"},\n    {\"content\": \"This is another test document.\"}\n]\ndb.add(documents)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>List[Dict[str, str]]</code> <p>A list of dictionaries containing the document content.</p> required <code>shared_id</code> <code>Optional[bool]</code> <p>Whether to use a shared ID for all documents. Defaults to False.</p> <code>False</code> Source code in <code>yosemite/ml/database.py</code> <pre><code>def add(self, documents: List[Dict[str, str]], shared_id: Optional[bool] = False):\n    \"\"\"\n    A method to add documents to the Whoosh index.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.create()\n        documents = [\n            {\"content\": \"This is a test document.\"},\n            {\"content\": \"This is another test document.\"}\n        ]\n        db.add(documents)\n        ```\n\n    Args:\n        documents (List[Dict[str, str]]): A list of dictionaries containing the document content.\n        shared_id (Optional[bool], optional): Whether to use a shared ID for all documents. Defaults to False.\n    \"\"\"\n    if not self.ix:\n        self.create()\n    writer = self.ix.writer()\n    chunker = Chunker()\n    embedder = SentenceTransformer(self.model_name)\n    for doc in documents:\n        if shared_id:\n            doc_id = \"shared\"\n        else:\n            doc_id = doc.get(\"id\", str(uuid.uuid4()))\n        doc_content = doc[\"content\"]\n        chunks = chunker.chunk_text(doc_content)\n        vectors = [embedder.embed([chunk])[0][1] for chunk in chunks]\n        writer.add_document(id=doc_id, content=doc_content, chunks=\"\\n\".join(chunks), vectors=vectors)\n    writer.commit()\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.create","title":"<code>create(dir=None)</code>","text":"<p>A method to create a new Whoosh index.</p> Example <pre><code>db = YosemiteDatabase()\ndb.create()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The directory where the Whoosh index will be stored. Defaults to None.</p> <code>None</code> Source code in <code>yosemite/ml/database.py</code> <pre><code>def create(self, dir: Optional[str] = None):\n    \"\"\"\n    A method to create a new Whoosh index.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.create()\n        ```\n\n    Args:\n        dir (str, optional): The directory where the Whoosh index will be stored. Defaults to None.\n    \"\"\"\n    if self.schema is None:\n        if self.analyzer == \"standard\":\n            self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=StandardAnalyzer(), stored=True), \n                                 chunks=TEXT(stored=True), vectors=STORED)\n        elif self.analyzer == \"fancy\":\n            self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=FancyAnalyzer(), stored=True), \n                                 chunks=TEXT(stored=True), vectors=STORED)\n        elif self.analyzer == \"language\":\n            self.schema = Schema(id=ID(stored=True), content=TEXT(analyzer=LanguageAnalyzer(), stored=True), \n                                 chunks=TEXT(stored=True), vectors=STORED)\n        elif self.analyzer == \"keyword\":\n            self.schema = Schema(id=ID(stored=True), content=KEYWORD(analyzer=KeywordAnalyzer(), stored=True), \n                                 chunks=TEXT(stored=True), vectors=STORED)\n\n    if dir is None:\n        self.index_dir = \"./databases/db\"\n    else:\n        self.index_dir = dir\n    os.makedirs(self.index_dir, exist_ok=True)\n    self.ix = whoosh_index.create_in(self.index_dir, self.schema)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.load","title":"<code>load(dir)</code>","text":"<p>A method to load an existing Whoosh index.</p> Example <pre><code>db = YosemiteDatabase()\ndb.load(\"./databases/db\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The directory where the Whoosh index is stored.</p> required Source code in <code>yosemite/ml/database.py</code> <pre><code>def load(self, dir: str):\n    \"\"\"\n    A method to load an existing Whoosh index.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.load(\"./databases/db\")\n        ```\n\n    Args:\n        dir (str): The directory where the Whoosh index is stored.\n    \"\"\"\n    self.index_dir = dir\n    if not os.path.exists(self.index_dir):\n        raise FileNotFoundError(f\"Index directory {self.index_dir} does not exist.\")\n    if not whoosh_index.exists_in(self.index_dir):\n        raise FileNotFoundError(f\"Index does not exist in directory {self.index_dir}.\")\n    self.ix = whoosh_index.open_dir(self.index_dir)\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.load_dataset","title":"<code>load_dataset(path, id_column, content_column)</code>","text":"<p>A method to load a CSV dataset into the Whoosh index.</p> Example <pre><code>db = YosemiteDatabase()\ndb.create()\ndb.load_dataset(\"data.csv\", \"id\", \"content\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the CSV dataset.</p> required <code>id_column</code> <code>str</code> <p>The name of the column containing the document IDs.</p> required <code>content_column</code> <code>str</code> <p>The name of the column containing the document content.</p> required Source code in <code>yosemite/ml/database.py</code> <pre><code>def load_dataset(self, path: str, id_column: str, content_column: str):\n    \"\"\"\n    A method to load a CSV dataset into the Whoosh index.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.create()\n        db.load_dataset(\"data.csv\", \"id\", \"content\")\n        ```\n\n    Args:\n        path (str): The path to the CSV dataset.\n        id_column (str): The name of the column containing the document IDs.\n        content_column (str): The name of the column containing the document content.\n    \"\"\"\n    if not self.ix:\n        self.create()\n    df = pd.read_csv(path)\n    writer = self.ix.writer()\n    chunker = Chunker()\n    embedder = SentenceTransformer(self.model_name)\n    for _, row in df.iterrows():\n        doc_id = str(row[id_column])\n        doc_content = row[content_column]\n        chunks = chunker.chunk_text(doc_content)\n        vectors = [embedder.embed([chunk])[0][1] for chunk in chunks]\n        writer.add_document(id=doc_id, content=doc_content, chunks=\"\\n\".join(chunks), vectors=vectors)\n    writer.commit()\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.load_docs","title":"<code>load_docs(dir)</code>","text":"<p>A very powerful method to load documents from a directory into the Whoosh index. Supports .txt, .pdf, and .epub files.</p> Example <pre><code>db = YosemiteDatabase()\ndb.create()\ndb.load_docs(\"documents\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The directory containing the documents.</p> required Source code in <code>yosemite/ml/database.py</code> <pre><code>def load_docs(self, dir: str):\n    \"\"\"\n    A very powerful method to load documents from a directory into the Whoosh index. Supports .txt, .pdf, and .epub files.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.create()\n        db.load_docs(\"documents\")\n        ```\n\n    Args:\n        dir (str): The directory containing the documents.\n    \"\"\"\n    if not self.ix:\n        self.create()\n    if not os.path.exists(dir):\n        raise FileNotFoundError(f\"Directory {dir} does not exist.\")\n\n    writer = self.ix.writer()\n    chunker = Chunker()\n    embedder = SentenceTransformer(self.model_name)\n    for file_path in os.listdir(dir):\n        file_path = os.path.join(dir, file_path)\n        if file_path.endswith(\".txt\"):\n            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n                content = file.read()\n        elif file_path.endswith(\".pdf\"):\n            with open(file_path, \"rb\") as file:\n                reader = PdfReader(file)\n                content = \" \".join(page.extract_text() for page in reader.pages)\n        elif file_path.endswith(\".epub\"):\n            book = epub.read_epub(file_path)\n            content = \" \".join(item.get_content().decode(\"utf-8\") for item in book.get_items_of_type(9))\n        else:\n            continue\n\n        doc_id = str(uuid.uuid4())\n        chunks = chunker.chunk_text(content)\n        vectors = [embedder.embed([chunk])[0][1] for chunk in chunks]\n        writer.add_document(id=doc_id, content=content, chunks=\"\\n\".join(chunks), vectors=vectors)\n    writer.commit()\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.search","title":"<code>search(query, fields=None, k=5)</code>","text":"<p>A method to search the Whoosh &amp; Annoy index.</p> Example <pre><code>db = YosemiteDatabase()\ndb.load(\"./databases/db\")\nresults = db.search(\"test\")\nfor doc_id, chunk, vector in results:\n    print(f\"Document ID: {doc_id}\")\n    print(f\"Chunk: {chunk}\")\n    print(f\"Vector: {vector}\")\n    print(\"---\")\n</code></pre> <pre><code>Document ID: 1\nChunk: This is a test document.\nVector: [0.1, 0.2, 0.3, ...]\n---\nDocument ID: 2\nChunk: This is another test document.\nVector: [0.4, 0.5, 0.6, ...]\n---\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query.</p> required <code>fields</code> <code>Optional[List[str]]</code> <p>The fields to search in. Defaults to None.</p> <code>None</code> <code>k</code> <code>int</code> <p>The number of results to return. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Tuple[str, str, List[float]]]</code> <p>List[Tuple[str, str, List[float]]]: A list of tuples containing the document ID, chunk, and vector.</p> Source code in <code>yosemite/ml/database.py</code> <pre><code>def search(self, query: str, fields: Optional[List[str]] = None, k: int = 5) -&gt; List[Tuple[str, str, List[float]]]:\n    \"\"\"\n    A method to search the Whoosh &amp; Annoy index.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.load(\"./databases/db\")\n        results = db.search(\"test\")\n        for doc_id, chunk, vector in results:\n            print(f\"Document ID: {doc_id}\")\n            print(f\"Chunk: {chunk}\")\n            print(f\"Vector: {vector}\")\n            print(\"---\")\n        ```\n\n        ```bash\n        Document ID: 1\n        Chunk: This is a test document.\n        Vector: [0.1, 0.2, 0.3, ...]\n        ---\n        Document ID: 2\n        Chunk: This is another test document.\n        Vector: [0.4, 0.5, 0.6, ...]\n        ---\n        ```\n\n    Args:\n        query (str): The search query.\n        fields (Optional[List[str]], optional): The fields to search in. Defaults to None.\n        k (int, optional): The number of results to return. Defaults to 5.\n\n    Returns:\n        List[Tuple[str, str, List[float]]]: A list of tuples containing the document ID, chunk, and vector.\n    \"\"\"\n    if not self.ix:\n        raise ValueError(\"Index has not been built or loaded.\")\n\n    with self.ix.searcher() as searcher:\n        if fields is None:\n            parser = QueryParser(\"content\", schema=self.schema)\n        else:\n            parser = MultifieldParser(fields, schema=self.schema)\n        try:\n            q = parser.parse(query)\n            results = searcher.search(q, limit=k)\n            embedder = SentenceTransformer(self.model_name)\n            query_vector = embedder.embed([query])[0][1]\n            ranked_results = []\n            for hit in results:\n                doc_id = hit[\"id\"]\n                doc_content = hit[\"content\"]\n                doc_vectors = hit[\"vectors\"]\n                if not self.dimension:\n                    self.dimension = len(doc_vectors[0])\n                index = AnnoyIndex(self.dimension, 'angular')\n                for i, vector in enumerate(doc_vectors):\n                    index.add_item(i, vector)\n                index.build(10)\n                indices = index.get_nns_by_vector(query_vector, k, include_distances=False)\n                for idx in indices:\n                    chunk = hit[\"chunks\"].split(\"\\n\")[idx]\n                    ranked_results.append((doc_id, chunk, doc_vectors[idx]))\n            return ranked_results\n        except QueryParserError as e:\n            print(f\"QueryParserError: {e}\")\n            return []\n</code></pre>"},{"location":"api/ml/data/yosemite.ml.data.yosemite/#yosemite.ml.database.YosemiteDatabase.search_and_rank","title":"<code>search_and_rank(query, k=5)</code>","text":"<p>A method to search and rank the Whoosh &amp; Annoy index.</p> Example <pre><code>db = YosemiteDatabase()\ndb.load(\"./databases/db\")\nresults = db.search_and_rank(\"test\")\nfor doc_id, chunk, score in results:\n    print(f\"Document ID: {doc_id}\")\n    print(f\"Chunk: {chunk}\")\n    print(f\"Score: {score}\")\n    print(\"---\")\n</code></pre> <pre><code>Document ID: 1\nChunk: This is a test document.\nScore: 0.9\n---\nDocument ID: 2\nChunk: This is another test document.\nScore: 0.8\n---\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query.</p> required <code>k</code> <code>int</code> <p>The number of results to return. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Tuple[str, str, float]]</code> <p>List[Tuple[str, str, float]]: A list of tuples containing the document ID, chunk, and score.</p> Source code in <code>yosemite/ml/database.py</code> <pre><code>def search_and_rank(self, query: str, k: int = 5) -&gt; List[Tuple[str, str, float]]:\n    \"\"\"\n    A method to search and rank the Whoosh &amp; Annoy index.\n\n    Example:\n        ```python\n        db = YosemiteDatabase()\n        db.load(\"./databases/db\")\n        results = db.search_and_rank(\"test\")\n        for doc_id, chunk, score in results:\n            print(f\"Document ID: {doc_id}\")\n            print(f\"Chunk: {chunk}\")\n            print(f\"Score: {score}\")\n            print(\"---\")\n        ```\n\n        ```bash\n        Document ID: 1\n        Chunk: This is a test document.\n        Score: 0.9\n        ---\n        Document ID: 2\n        Chunk: This is another test document.\n        Score: 0.8\n        ---\n        ```\n\n    Args:\n        query (str): The search query.\n        k (int, optional): The number of results to return. Defaults to 5.\n\n    Returns:\n        List[Tuple[str, str, float]]: A list of tuples containing the document ID, chunk, and score.\n    \"\"\"\n    if not self.ix:\n        raise ValueError(\"Index has not been built or loaded.\")\n    with self.ix.searcher() as searcher:\n        parser = QueryParser(\"content\", schema=self.schema)\n        try:\n            q = parser.parse(query)\n            whoosh_results = searcher.search(q, limit=k)\n            whoosh_chunks = [hit[\"chunks\"] for hit in whoosh_results]\n        except QueryParserError as e:\n            print(f\"QueryParserError: {e}\")\n            whoosh_chunks = []\n    embedder = SentenceTransformer(self.model_name)\n    query_vector = embedder.embed([query])[0][1]\n    vector_results = []\n    for doc_id, doc_chunks, doc_vectors in zip(self.document_ids, self.sentences, self.vectors):\n        if not self.dimension:\n            self.dimension = len(doc_vectors[0])\n        index = AnnoyIndex(self.dimension, 'angular')\n        for i, vector in enumerate(doc_vectors):\n            index.add_item(i, vector)\n        index.build(10)\n        indices = index.get_nns_by_vector(query_vector, k, include_distances=False)\n        for idx in indices:\n            vector_results.append((doc_id, doc_chunks[idx]))\n\n    combined_results = whoosh_chunks + [chunk for _, chunk in vector_results]\n    cross_encode = CrossEncode()\n    ranked_results = cross_encode.rank(query, combined_results, [])\n    return [(doc_id, chunk, score) for (doc_id, chunk), score in ranked_results]\n</code></pre>"},{"location":"api/ml/llm/yosemite.ml.llm/","title":"LLMs","text":""},{"location":"api/ml/llm/yosemite.ml.llm/#yosemite.llms.llm.LLM","title":"<code>LLM</code>","text":"<p>A simplified interface for 'deploying' LLMs in your code.</p> <pre><code>from yosemite.llms import LLM\n\nllm = LLM(provider=\"anthropic\")\ncompletion = llm.invoke(\n    query=\"What is the capital of France?\"\n)\n</code></pre> <pre><code>The capital of France is Paris.\n</code></pre> <pre><code>from pydantic import BaseModel\n\nclass Completion(BaseModel):\n    message: str\n\ninstructor = LLM(provider=\"openai\")\ncompletion = instructor.invoke(\n    query=\"What is the capital of France?\",\n    pydantic_model=Completion\n)\n</code></pre> <pre><code>{\n    \"message\": \"The capital of France is Paris.\"\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>str</code> <p>The LLM provider to use. Supported providers are \"openai\", \"anthropic\", and \"nvidia\".</p> required <code>api_key</code> <code>str</code> <p>The API key for the provider. Defaults to None.</p> <code>None</code> <code>base_url</code> <code>str</code> <p>The base URL for the provider. Defaults to None.</p> <code>None</code> <p>Methods:</p> Name Description <code>invoke</code> <p>Invokes the LLM with the given query.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provider is not supported or the API key is not available.</p> Source code in <code>yosemite/llms/llm.py</code> <pre><code>class LLM:\n    \"\"\"\n    A simplified interface for 'deploying' LLMs in your code.\n\n    ```python\n    from yosemite.llms import LLM\n\n    llm = LLM(provider=\"anthropic\")\n    completion = llm.invoke(\n        query=\"What is the capital of France?\"\n    )\n    ```\n\n    ```bash\n    The capital of France is Paris.\n    ```\n\n    ```python\n    from pydantic import BaseModel\n\n    class Completion(BaseModel):\n        message: str\n\n    instructor = LLM(provider=\"openai\")\n    completion = instructor.invoke(\n        query=\"What is the capital of France?\",\n        pydantic_model=Completion\n    )\n    ```\n\n    ```bash\n    {\n        \"message\": \"The capital of France is Paris.\"\n    }\n    ```\n\n    Args:\n        provider (str): The LLM provider to use. Supported providers are \"openai\", \"anthropic\", and \"nvidia\".\n        api_key (str, optional): The API key for the provider. Defaults to None.\n        base_url (str, optional): The base URL for the provider. Defaults to None.\n\n    Methods:\n        invoke: Invokes the LLM with the given query.\n\n    Raises:\n        ValueError: If the provider is not supported or the API key is not available.\n    \"\"\"\n\n\n    def __init__(self, provider: str, api_key: Optional[str] = None, base_url: Optional[str] = None):\n        self.provider = provider.lower()\n        self.api_key = api_key\n        self.base_url = base_url\n\n        if self.provider == \"openai\":\n            if self.api_key is None:\n                self.api_key = os.getenv(\"OPENAI_API_KEY\")\n            if self.api_key is None:\n                raise ValueError(\"OpenAI API key is not available\")\n            self.llm = instructor.patch(OpenAI(api_key=self.api_key))\n        elif self.provider == \"anthropic\":\n            if self.api_key is None:\n                self.api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n            if self.api_key is None:\n                raise ValueError(\"Anthropic API key is not available\")\n            self.client = anthropic.Anthropic(api_key=self.api_key)\n        elif self.provider == \"nvidia\":\n            if self.api_key is None:\n                self.api_key = os.getenv(\"NVIDIA_API_KEY\")\n            if self.api_key is None:\n                raise ValueError(\"NVIDIA API key is not available\")\n            if self.base_url is None:\n                self.base_url = \"https://integrate.api.nvidia.com/v1\"\n            self.llm = OpenAI(base_url=self.base_url, api_key=self.api_key)\n        else:\n            raise ValueError(f\"Unsupported provider: {self.provider}\")\n\n    def invoke(\n        self,\n        system: Optional[str] = None,\n        query: Optional[str] = None,\n        model: str = \"gpt-3.5-turbo-1106\",\n        pydantic_model=None,\n        max_tokens: int = 1024,\n        temperature: float = 0.5,\n        top_p: float = 1,\n        stream: bool = False,\n    ):\n        \"\"\"\n        Generates a completion for the given query.\n\n        Example:\n        ```python\n        completion = llm.invoke(\n            query=\"What is the capital of France?\"\n        )\n        ```\n\n        Args:\n            system (str, optional): The system prompt. Defaults to None.\n            query (str, optional): The user query. Defaults to None.\n            model (str, optional): The model to use. Defaults to \"gpt-3.5-turbo-1106\".\n            pydantic_model (Any, optional): The Pydantic model to use for the response. Defaults to None.\n            max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 1024.\n            temperature (float, optional): The sampling temperature. Defaults to 0.5.\n            top_p (float, optional): The nucleus sampling parameter. Defaults to 1.\n            stream (bool, optional): Whether to stream the response. Defaults to False.\n\n        Returns:\n            Any: The completion response.\n        \"\"\"\n        if query is None:\n            raise ValueError(\"Query is required for instruct()\")\n\n        if system is None:\n            system = \"You are a helpful assistant.\"\n\n        if self.provider == \"openai\":\n            if model == \"3\":\n                model = \"gpt-3.5-turbo-1106\"\n            elif model == \"4\":\n                model = \"gpt-4-turbo-preview\"\n\n            completion = self.llm.chat.completions.create(\n                model=model,\n                messages=[\n                    {\"role\": \"system\", \"content\": system},\n                    {\"role\": \"user\", \"content\": query},\n                ],\n                response_model=pydantic_model,\n            )\n\n            if pydantic_model is None:\n                return completion.choices[0].message.content\n            else:\n                return completion.completion\n\n        elif self.provider == \"anthropic\":\n            if system is None:\n                system_prompt = \"You are a helpful assistant.\"\n            else:\n                system_prompt = system\n\n            if model is None:\n                model = \"claude-3-opus-20240229\"\n\n            message = self.client.messages.create(\n                model=model,\n                max_tokens=max_tokens,\n                temperature=temperature,\n                system=system_prompt,\n                messages=[\n                    {\n                        \"role\": \"user\",\n                        \"content\": [\n                            {\n                                \"type\": \"text\",\n                                \"text\": query\n                            }\n                        ]\n                    }\n                ]\n            )\n            return message.content\n        elif self.provider == \"nvidia\":\n            completion = self.llm.chat.completions.create(\n                model=model,\n                messages=[{\"role\": \"user\", \"content\": query}],\n                temperature=temperature,\n                top_p=top_p,\n                max_tokens=max_tokens,\n                stream=stream\n            )\n\n            if stream:\n                response = \"\"\n                for chunk in completion:\n                    if chunk.choices[0].delta.content is not None:\n                        response += chunk.choices[0].delta.content\n                        print(chunk.choices[0].delta.content, end=\"\")\n                return response\n            else:\n                return completion.choices[0].message.content\n</code></pre>"},{"location":"api/ml/llm/yosemite.ml.llm/#yosemite.llms.llm.LLM.invoke","title":"<code>invoke(system=None, query=None, model='gpt-3.5-turbo-1106', pydantic_model=None, max_tokens=1024, temperature=0.5, top_p=1, stream=False)</code>","text":"<p>Generates a completion for the given query.</p> <p>Example: <pre><code>completion = llm.invoke(\n    query=\"What is the capital of France?\"\n)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>system</code> <code>str</code> <p>The system prompt. Defaults to None.</p> <code>None</code> <code>query</code> <code>str</code> <p>The user query. Defaults to None.</p> <code>None</code> <code>model</code> <code>str</code> <p>The model to use. Defaults to \"gpt-3.5-turbo-1106\".</p> <code>'gpt-3.5-turbo-1106'</code> <code>pydantic_model</code> <code>Any</code> <p>The Pydantic model to use for the response. Defaults to None.</p> <code>None</code> <code>max_tokens</code> <code>int</code> <p>The maximum number of tokens to generate. Defaults to 1024.</p> <code>1024</code> <code>temperature</code> <code>float</code> <p>The sampling temperature. Defaults to 0.5.</p> <code>0.5</code> <code>top_p</code> <code>float</code> <p>The nucleus sampling parameter. Defaults to 1.</p> <code>1</code> <code>stream</code> <code>bool</code> <p>Whether to stream the response. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The completion response.</p> Source code in <code>yosemite/llms/llm.py</code> <pre><code>def invoke(\n    self,\n    system: Optional[str] = None,\n    query: Optional[str] = None,\n    model: str = \"gpt-3.5-turbo-1106\",\n    pydantic_model=None,\n    max_tokens: int = 1024,\n    temperature: float = 0.5,\n    top_p: float = 1,\n    stream: bool = False,\n):\n    \"\"\"\n    Generates a completion for the given query.\n\n    Example:\n    ```python\n    completion = llm.invoke(\n        query=\"What is the capital of France?\"\n    )\n    ```\n\n    Args:\n        system (str, optional): The system prompt. Defaults to None.\n        query (str, optional): The user query. Defaults to None.\n        model (str, optional): The model to use. Defaults to \"gpt-3.5-turbo-1106\".\n        pydantic_model (Any, optional): The Pydantic model to use for the response. Defaults to None.\n        max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 1024.\n        temperature (float, optional): The sampling temperature. Defaults to 0.5.\n        top_p (float, optional): The nucleus sampling parameter. Defaults to 1.\n        stream (bool, optional): Whether to stream the response. Defaults to False.\n\n    Returns:\n        Any: The completion response.\n    \"\"\"\n    if query is None:\n        raise ValueError(\"Query is required for instruct()\")\n\n    if system is None:\n        system = \"You are a helpful assistant.\"\n\n    if self.provider == \"openai\":\n        if model == \"3\":\n            model = \"gpt-3.5-turbo-1106\"\n        elif model == \"4\":\n            model = \"gpt-4-turbo-preview\"\n\n        completion = self.llm.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": system},\n                {\"role\": \"user\", \"content\": query},\n            ],\n            response_model=pydantic_model,\n        )\n\n        if pydantic_model is None:\n            return completion.choices[0].message.content\n        else:\n            return completion.completion\n\n    elif self.provider == \"anthropic\":\n        if system is None:\n            system_prompt = \"You are a helpful assistant.\"\n        else:\n            system_prompt = system\n\n        if model is None:\n            model = \"claude-3-opus-20240229\"\n\n        message = self.client.messages.create(\n            model=model,\n            max_tokens=max_tokens,\n            temperature=temperature,\n            system=system_prompt,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"text\",\n                            \"text\": query\n                        }\n                    ]\n                }\n            ]\n        )\n        return message.content\n    elif self.provider == \"nvidia\":\n        completion = self.llm.chat.completions.create(\n            model=model,\n            messages=[{\"role\": \"user\", \"content\": query}],\n            temperature=temperature,\n            top_p=top_p,\n            max_tokens=max_tokens,\n            stream=stream\n        )\n\n        if stream:\n            response = \"\"\n            for chunk in completion:\n                if chunk.choices[0].delta.content is not None:\n                    response += chunk.choices[0].delta.content\n                    print(chunk.choices[0].delta.content, end=\"\")\n            return response\n        else:\n            return completion.choices[0].message.content\n</code></pre>"},{"location":"api/ml/transformers/ce/","title":"Cross Encoder","text":"<pre><code>from yosemite.ml.transformers import CrossEncoder\n</code></pre> <p>Initializes the CrossEncoder with a specified model. Default model is \"cross-encoder/ms-marco-MiniLM-L-12-v2\".</p> Example <pre><code>sentences = [\n    \"The cat is sitting on the mat.\",\n    \"The dog is playing in the park.\",\n    \"Paris is the capital of France.\",\n    \"London is the capital of England.\",\n    \"A feline is resting on the rug.\",\n]\n\ncross_encode = CrossEncoder()\nquery = \"What is the capital of France?\"\nranked_sentences = cross_encode.rank(query, sentences1, sentences2)\n</code></pre> <pre><code>CrossEncoder results:\nParis is the capital of France. (Score: 0.99)\nLondon is the capital of England. (Score: 0.98)\nThe cat is sitting on the mat. (Score: 0.97)\nThe dog is playing in the park. (Score: 0.96)\nA feline is resting on the rug. (Score: 0.95)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <p>str, optional The name of the CrossEncoder model to use (default is \"cross-encoder/ms-marco-MiniLM-L-12-v2\")</p> <code>'cross-encoder/ms-marco-MiniLM-L-12-v2'</code> <code>max_length</code> <p>int, optional The maximum length of the input sequences (default is None)</p> <code>None</code> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>class CrossEncoder:\n    \"\"\"\n    Initializes the CrossEncoder with a specified model. Default model is \"cross-encoder/ms-marco-MiniLM-L-12-v2\".\n\n    Example:\n        ```python\n        sentences = [\n            \"The cat is sitting on the mat.\",\n            \"The dog is playing in the park.\",\n            \"Paris is the capital of France.\",\n            \"London is the capital of England.\",\n            \"A feline is resting on the rug.\",\n        ]\n\n        cross_encode = CrossEncoder()\n        query = \"What is the capital of France?\"\n        ranked_sentences = cross_encode.rank(query, sentences1, sentences2)\n        ```\n\n        ```bash\n        CrossEncoder results:\n        Paris is the capital of France. (Score: 0.99)\n        London is the capital of England. (Score: 0.98)\n        The cat is sitting on the mat. (Score: 0.97)\n        The dog is playing in the park. (Score: 0.96)\n        A feline is resting on the rug. (Score: 0.95)\n        ```\n\n    Args:\n        model_name : str, optional\n            The name of the CrossEncoder model to use (default is \"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n        max_length : int, optional\n            The maximum length of the input sequences (default is None)\n    \"\"\"\n    def __init__(self, model_name: str = \"cross-encoder/ms-marco-MiniLM-L-12-v2\", max_length: int = None):\n        self.model = CrossEncoderModel(model_name, max_length=max_length)\n\n    def rank(self, query: str, x: List[str], y: List[str]) -&gt; List[Tuple[str, float]]:\n        \"\"\"\n        Re-ranks sentences formed by combining two lists based on their relevance to a single query using the CrossEncoder model.\n\n        Example:\n            ```python\n            from sentence_transformers import CrossEncoder\n\n            CrossEncoder.rank(\"What is the capital of France?\", [\"Paris is the capital of France.\"], [\"London is the capital of England.\"])\n            ```\n\n        Args:\n            query : str\n                The query to use for re-ranking\n            x : List[str]\n                The first list of sentences\n            y : List[str]\n                The second list of sentences\n\n        Returns:\n            List[Tuple[str, float]]\n                A list of ranked sentences with their scores\n        \"\"\"\n        sentences = x + y\n        if not sentences:\n            return []\n\n        scores = self.model.predict([(query, sentence) for sentence in sentences])\n\n        ranked_sentences = [(sentence, score) for sentence, score in sorted(zip(sentences, scores), key=lambda x: x[1], reverse=True)]\n\n        return ranked_sentences\n</code></pre>"},{"location":"api/ml/transformers/ce/#yosemite.ml.transformers.CrossEncoder.rank","title":"<code>rank(query, x, y)</code>","text":"<p>Re-ranks sentences formed by combining two lists based on their relevance to a single query using the CrossEncoder model.</p> Example <pre><code>from sentence_transformers import CrossEncoder\n\nCrossEncoder.rank(\"What is the capital of France?\", [\"Paris is the capital of France.\"], [\"London is the capital of England.\"])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>str The query to use for re-ranking</p> required <code>x</code> <p>List[str] The first list of sentences</p> required <code>y</code> <p>List[str] The second list of sentences</p> required <p>Returns:</p> Type Description <code>List[Tuple[str, float]]</code> <p>List[Tuple[str, float]] A list of ranked sentences with their scores</p> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>def rank(self, query: str, x: List[str], y: List[str]) -&gt; List[Tuple[str, float]]:\n    \"\"\"\n    Re-ranks sentences formed by combining two lists based on their relevance to a single query using the CrossEncoder model.\n\n    Example:\n        ```python\n        from sentence_transformers import CrossEncoder\n\n        CrossEncoder.rank(\"What is the capital of France?\", [\"Paris is the capital of France.\"], [\"London is the capital of England.\"])\n        ```\n\n    Args:\n        query : str\n            The query to use for re-ranking\n        x : List[str]\n            The first list of sentences\n        y : List[str]\n            The second list of sentences\n\n    Returns:\n        List[Tuple[str, float]]\n            A list of ranked sentences with their scores\n    \"\"\"\n    sentences = x + y\n    if not sentences:\n        return []\n\n    scores = self.model.predict([(query, sentence) for sentence in sentences])\n\n    ranked_sentences = [(sentence, score) for sentence, score in sorted(zip(sentences, scores), key=lambda x: x[1], reverse=True)]\n\n    return ranked_sentences\n</code></pre>"},{"location":"api/ml/transformers/loss/","title":"Loss","text":"<pre><code>from yosemite.ml.transformers import Loss\n</code></pre> <p>Initializes the Loss object with a specified loss type, data format, and model.</p> Example <pre><code>loss = Loss(loss_type=\"BatchAllTripletLoss\", data_format=\"single_sentences\")\nprint(f\"Initialized loss: {loss.loss}\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>loss_type</code> <p>str The type of loss function to use</p> required <code>data_format</code> <p>str The format of the input data (single_sentences, sentence_pairs, or triplets)</p> required <code>model_name</code> <p>str, optional The name of the SentenceTransformer model to use (default is \"all-MiniLM-L6-v2\")</p> <code>'all-MiniLM-L6-v2'</code> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>class Loss:\n    \"\"\"\n    Initializes the Loss object with a specified loss type, data format, and model.\n\n    Example:\n        ```python\n        loss = Loss(loss_type=\"BatchAllTripletLoss\", data_format=\"single_sentences\")\n        print(f\"Initialized loss: {loss.loss}\")\n        ```\n\n    Args:\n        loss_type : str\n            The type of loss function to use\n        data_format : str\n            The format of the input data (single_sentences, sentence_pairs, or triplets)\n        model_name : str, optional\n            The name of the SentenceTransformer model to use (default is \"all-MiniLM-L6-v2\")\n    \"\"\"\n    def __init__(self, loss_type: str, data_format: str, model_name: str = \"all-MiniLM-L6-v2\"):\n        self.model = SentenceTransformerModel(model_name)\n        self.loss = self._initialize_loss(loss_type, data_format)\n\n    def _initialize_loss(self, loss_type: str, data_format: str):\n        if data_format == \"single_sentences\":\n            return self._init_single_sentence_loss(loss_type)\n        elif data_format == \"sentence_pairs\":\n            return self._init_sentence_pair_loss(loss_type)\n        elif data_format == \"triplets\":\n            return self._init_triplet_loss(loss_type)\n        else:\n            raise ValueError(\"Unsupported data format\")\n\n    def _init_single_sentence_loss(self, loss_type: str):\n        if loss_type == \"BatchAllTripletLoss\":\n            return losses.BatchAllTripletLoss(model=self.model)\n        elif loss_type == \"BatchHardTripletLoss\":\n            return losses.BatchHardTripletLoss(model=self.model)\n        elif loss_type == \"BatchSemiHardTripletLoss\":\n            return losses.BatchSemiHardTripletLoss(model=self.model)\n        else:\n            raise ValueError(\"Unsupported loss type for single sentences\")\n\n    def _init_sentence_pair_loss(self, loss_type: str):\n        if loss_type == \"SoftmaxLoss\":\n            return losses.SoftmaxLoss(model=self.model)\n        elif loss_type == \"ContrastiveLoss\":\n            return losses.ContrastiveLoss(model=self.model)\n        else:\n            raise ValueError(\"Unsupported loss type for sentence pairs\")\n\n    def _init_triplet_loss(self, loss_type: str):\n        if loss_type == \"TripletLoss\":\n            return losses.TripletLoss(model=self.model)\n        elif loss_type == \"MultipleNegativesRankingLoss\":\n            return losses.MultipleNegativesRankingLoss(model=self.model)\n        else:\n            raise ValueError(\"Unsupported loss type for triplets\")\n</code></pre>"},{"location":"api/ml/transformers/semsearch/","title":"Semantic Search","text":"<pre><code>from yosemite.ml.transformers import SemanticSearch\n</code></pre> <p>Constructs all the necessary Args for the SemanticSearch object.</p> Example <pre><code>semantic_search = SemanticSearch()\ncorpus_embeddings = semantic_search.encode_corpus(sentences1 + sentences2)\nresults = semantic_search.search(query, corpus_embeddings, sentences1 + sentences2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <p>str, optional The name of the SentenceTransformer model to use (default is \"all-MiniLM-L6-v2\")</p> <code>'all-MiniLM-L6-v2'</code> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>class SemanticSearch:\n    \"\"\"\n    Constructs all the necessary Args for the SemanticSearch object.\n\n    Example:\n        ```python\n        semantic_search = SemanticSearch()\n        corpus_embeddings = semantic_search.encode_corpus(sentences1 + sentences2)\n        results = semantic_search.search(query, corpus_embeddings, sentences1 + sentences2)\n        ```\n\n    Args:\n        model_name : str, optional\n            The name of the SentenceTransformer model to use (default is \"all-MiniLM-L6-v2\")\n    \"\"\"\n    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n        self.model = SentenceTransformerModel(model_name)\n\n    def encode_corpus(self, corpus: List[str]) -&gt; torch.Tensor:\n        \"\"\"\n        Encodes a list of sentences into embeddings.\n\n        Example:\n            ```python\n            corpus = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\n            semantic_search = SemanticSearch()\n            corpus_embeddings = semantic_search.encode_corpus(corpus)\n            ```\n\n        Args:\n            corpus : List[str]\n                The list of sentences to encode\n\n        Returns:\n            torch.Tensor\n                A tensor containing the embeddings of the sentences\n        \"\"\"\n        return self.model.encode(corpus, convert_to_tensor=True)\n\n    def search(self, query: str, corpus_embeddings: torch.Tensor, corpus: List[str], top_k: int = 5) -&gt; List[Tuple[str, float]]:\n        \"\"\"\n        Performs semantic search on a list of sentences.\n\n        Example:\n            ```python\n            query = \"What is the capital of France?\"\n            semantic_search = SemanticSearch()\n            corpus_embeddings = semantic_search.encode_corpus(sentences1 + sentences2)\n            results = semantic_search.search(query, corpus_embeddings, sentences1 + sentences2)\n            ```\n\n        Args:\n            query : str\n                The query sentence\n            corpus_embeddings : torch.Tensor\n                The embeddings of the corpus sentences\n            corpus : List[str]\n                The list of sentences to search\n            top_k : int, optional\n                The number of results to return (default is 5)\n\n        Returns:\n            List[Tuple[str, float]]\n                A list of tuples, each containing a sentence from the corpus and its similarity score to the query\n        \"\"\"\n        query_embedding = self.model.encode(query, convert_to_tensor=True)\n        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n\n        # Check if top_k is within the valid range\n        top_k = min(top_k, len(corpus))\n\n        top_results = torch.topk(cos_scores, k=top_k)\n        return [(corpus[idx], score.item()) for score, idx in zip(top_results[0], top_results[1])]\n</code></pre>"},{"location":"api/ml/transformers/semsearch/#yosemite.ml.transformers.SemanticSearch.encode_corpus","title":"<code>encode_corpus(corpus)</code>","text":"<p>Encodes a list of sentences into embeddings.</p> Example <pre><code>corpus = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\nsemantic_search = SemanticSearch()\ncorpus_embeddings = semantic_search.encode_corpus(corpus)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>corpus</code> <p>List[str] The list of sentences to encode</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor A tensor containing the embeddings of the sentences</p> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>def encode_corpus(self, corpus: List[str]) -&gt; torch.Tensor:\n    \"\"\"\n    Encodes a list of sentences into embeddings.\n\n    Example:\n        ```python\n        corpus = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\n        semantic_search = SemanticSearch()\n        corpus_embeddings = semantic_search.encode_corpus(corpus)\n        ```\n\n    Args:\n        corpus : List[str]\n            The list of sentences to encode\n\n    Returns:\n        torch.Tensor\n            A tensor containing the embeddings of the sentences\n    \"\"\"\n    return self.model.encode(corpus, convert_to_tensor=True)\n</code></pre>"},{"location":"api/ml/transformers/semsearch/#yosemite.ml.transformers.SemanticSearch.search","title":"<code>search(query, corpus_embeddings, corpus, top_k=5)</code>","text":"<p>Performs semantic search on a list of sentences.</p> Example <pre><code>query = \"What is the capital of France?\"\nsemantic_search = SemanticSearch()\ncorpus_embeddings = semantic_search.encode_corpus(sentences1 + sentences2)\nresults = semantic_search.search(query, corpus_embeddings, sentences1 + sentences2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>str The query sentence</p> required <code>corpus_embeddings</code> <p>torch.Tensor The embeddings of the corpus sentences</p> required <code>corpus</code> <p>List[str] The list of sentences to search</p> required <code>top_k</code> <p>int, optional The number of results to return (default is 5)</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Tuple[str, float]]</code> <p>List[Tuple[str, float]] A list of tuples, each containing a sentence from the corpus and its similarity score to the query</p> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>def search(self, query: str, corpus_embeddings: torch.Tensor, corpus: List[str], top_k: int = 5) -&gt; List[Tuple[str, float]]:\n    \"\"\"\n    Performs semantic search on a list of sentences.\n\n    Example:\n        ```python\n        query = \"What is the capital of France?\"\n        semantic_search = SemanticSearch()\n        corpus_embeddings = semantic_search.encode_corpus(sentences1 + sentences2)\n        results = semantic_search.search(query, corpus_embeddings, sentences1 + sentences2)\n        ```\n\n    Args:\n        query : str\n            The query sentence\n        corpus_embeddings : torch.Tensor\n            The embeddings of the corpus sentences\n        corpus : List[str]\n            The list of sentences to search\n        top_k : int, optional\n            The number of results to return (default is 5)\n\n    Returns:\n        List[Tuple[str, float]]\n            A list of tuples, each containing a sentence from the corpus and its similarity score to the query\n    \"\"\"\n    query_embedding = self.model.encode(query, convert_to_tensor=True)\n    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n\n    # Check if top_k is within the valid range\n    top_k = min(top_k, len(corpus))\n\n    top_results = torch.topk(cos_scores, k=top_k)\n    return [(corpus[idx], score.item()) for score, idx in zip(top_results[0], top_results[1])]\n</code></pre>"},{"location":"api/ml/transformers/sentsim/","title":"Sentence Similarity","text":"<pre><code>from yosemite.ml.transformers import SentenceSimilarity\n</code></pre> <p>Constructs all the necessary Args for the SentenceSimilarity object.</p> Example <pre><code>sentence_similarity = SentenceSimilarity()\nsimilarities = sentence_similarity.compute_similarity(sentences1, sentences2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <p>str, optional The name of the SentenceTransformer model to use (default is \"all-MiniLM-L6-v2\")</p> <code>'all-MiniLM-L6-v2'</code> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>class SentenceSimilarity:\n    \"\"\"\n    Constructs all the necessary Args for the SentenceSimilarity object.\n\n    Example:\n        ```python\n        sentence_similarity = SentenceSimilarity()\n        similarities = sentence_similarity.compute_similarity(sentences1, sentences2)\n        ```\n\n    Args:\n        model_name : str, optional\n            The name of the SentenceTransformer model to use (default is \"all-MiniLM-L6-v2\")\n    \"\"\"\n    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n        self.model = SentenceTransformerModel(model_name)\n\n    def compute_similarity(self, sentences1: List[str], sentences2: List[str]) -&gt; List[Tuple[str, str, float]]:\n        \"\"\"\n        Computes the cosine similarity between two lists of sentences.\n\n        Example:\n            ```python\n            sentences1 = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\n            sentences2 = [\"A feline is resting on the rug.\", \"A canine is running in the garden.\", \"London is the capital of England.\"]\n            sentence_similarity = SentenceSimilarity()\n            similarities = sentence_similarity.compute_similarity(sentences1, sentences2)\n            ```\n\n        Args:\n            sentences1 : List[str]\n                The first list of sentences\n            sentences2 : List[str]\n                The second list of sentences\n\n        Returns:\n            List[Tuple[str, str, float]]\n                A list of tuples, each containing a pair of sentences and their cosine similarity\n        \"\"\"\n        embeddings1 = self.model.encode(sentences1, convert_to_tensor=True)\n        embeddings2 = self.model.encode(sentences2, convert_to_tensor=True)\n        cosine_scores = util.cos_sim(embeddings1, embeddings2)\n        return [(sentences1[i], sentences2[j], cosine_scores[i][j].item()) for i in range(len(sentences1)) for j in range(len(sentences2))]\n</code></pre>"},{"location":"api/ml/transformers/sentsim/#yosemite.ml.transformers.SentenceSimilarity.compute_similarity","title":"<code>compute_similarity(sentences1, sentences2)</code>","text":"<p>Computes the cosine similarity between two lists of sentences.</p> Example <pre><code>sentences1 = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\nsentences2 = [\"A feline is resting on the rug.\", \"A canine is running in the garden.\", \"London is the capital of England.\"]\nsentence_similarity = SentenceSimilarity()\nsimilarities = sentence_similarity.compute_similarity(sentences1, sentences2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sentences1</code> <p>List[str] The first list of sentences</p> required <code>sentences2</code> <p>List[str] The second list of sentences</p> required <p>Returns:</p> Type Description <code>List[Tuple[str, str, float]]</code> <p>List[Tuple[str, str, float]] A list of tuples, each containing a pair of sentences and their cosine similarity</p> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>def compute_similarity(self, sentences1: List[str], sentences2: List[str]) -&gt; List[Tuple[str, str, float]]:\n    \"\"\"\n    Computes the cosine similarity between two lists of sentences.\n\n    Example:\n        ```python\n        sentences1 = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\n        sentences2 = [\"A feline is resting on the rug.\", \"A canine is running in the garden.\", \"London is the capital of England.\"]\n        sentence_similarity = SentenceSimilarity()\n        similarities = sentence_similarity.compute_similarity(sentences1, sentences2)\n        ```\n\n    Args:\n        sentences1 : List[str]\n            The first list of sentences\n        sentences2 : List[str]\n            The second list of sentences\n\n    Returns:\n        List[Tuple[str, str, float]]\n            A list of tuples, each containing a pair of sentences and their cosine similarity\n    \"\"\"\n    embeddings1 = self.model.encode(sentences1, convert_to_tensor=True)\n    embeddings2 = self.model.encode(sentences2, convert_to_tensor=True)\n    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n    return [(sentences1[i], sentences2[j], cosine_scores[i][j].item()) for i in range(len(sentences1)) for j in range(len(sentences2))]\n</code></pre>"},{"location":"api/ml/transformers/transformer/","title":"Sentence Transformer","text":"<pre><code>from yosemite.ml.transformers import SentenceTransformer\n</code></pre> <p>Embeds sentences using the SentenceTransformer model.</p> Example <pre><code>sentences = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\nembedder = SentenceTransformer()\nembeddings = embedder.embed(sentences)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>str, optional The name of the SentenceTransformer model to use (default is \"paraphrase-MiniLM-L6-v2\")</p> <code>'paraphrase-MiniLM-L6-v2'</code> <p>Attributes:</p> Name Type Description <code>model</code> <p>SentenceTransformerModel The SentenceTransformer model used for embedding</p> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>class SentenceTransformer:\n    \"\"\"\n    Embeds sentences using the SentenceTransformer model.\n\n    Example:\n        ```python\n        sentences = [\"The cat is sitting on the mat.\", \"The dog is playing in the park.\", \"Paris is the capital of France.\"]\n        embedder = SentenceTransformer()\n        embeddings = embedder.embed(sentences)\n        ```\n\n    Args:\n        model : str, optional\n            The name of the SentenceTransformer model to use (default is \"paraphrase-MiniLM-L6-v2\")\n\n    Attributes:\n        model : SentenceTransformerModel\n            The SentenceTransformer model used for embedding\n    \"\"\"\n    def __init__(self, model: str = \"paraphrase-MiniLM-L6-v2\"):\n        self.model = SentenceTransformerModel(model)\n\n    def embed(self, sentences: List[str]) -&gt; List[Tuple[str, List[float]]]:\n        \"\"\"\n        Embeds a list of sentences using the SentenceTransformer model.\n\n        Args:\n            sentences : List[str]\n                The list of sentences to embed\n\n        Returns:\n            List[Tuple[str, List[float]]]\n                A list of tuples, each containing a sentence and its embedding\n        \"\"\"\n        if not sentences:\n            return []\n        return [(sentence, self.model.encode(sentence)) for sentence in sentences]\n</code></pre>"},{"location":"api/ml/transformers/transformer/#yosemite.ml.transformers.SentenceTransformer.embed","title":"<code>embed(sentences)</code>","text":"<p>Embeds a list of sentences using the SentenceTransformer model.</p> <p>Parameters:</p> Name Type Description Default <code>sentences</code> <p>List[str] The list of sentences to embed</p> required <p>Returns:</p> Type Description <code>List[Tuple[str, List[float]]]</code> <p>List[Tuple[str, List[float]]] A list of tuples, each containing a sentence and its embedding</p> Source code in <code>yosemite/ml/transformers.py</code> <pre><code>def embed(self, sentences: List[str]) -&gt; List[Tuple[str, List[float]]]:\n    \"\"\"\n    Embeds a list of sentences using the SentenceTransformer model.\n\n    Args:\n        sentences : List[str]\n            The list of sentences to embed\n\n    Returns:\n        List[Tuple[str, List[float]]]\n            A list of tuples, each containing a sentence and its embedding\n    \"\"\"\n    if not sentences:\n        return []\n    return [(sentence, self.model.encode(sentence)) for sentence in sentences]\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/","title":"CLI Inputs &amp; Dialogs","text":"<pre><code>from yosemite.tools import Input, Dialog\n\nname = Input().ask(\"What is your name?\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog","title":"<code>Dialog</code>","text":"Source code in <code>yosemite/tools/input.py</code> <pre><code>class Dialog:\n    def __init__(self):\n        \"\"\"\n        A lighweight for handling user inputs in the terminal.\n\n        Attributes:\n            ask: A method to prompt the user for input in the terminal.\n            confirm: A method to prompt the user for a yes/no confirmation.\n            asklist: A method to prompt the user to select from a list of choices.\n            radio: A method to prompt the user to select from a list of choices using a radio list.\n            checkbox: A method to prompt the user to select from a list of choices using a checkbox list.\n            button: A method to prompt the user to select from a list of choices using buttons.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def ask(message: str = None, title: str = None):\n        \"\"\"\n        Prompt for user input in the terminal.\n\n        Example:\n            ```python\n            from yosemite.tools.input import Dialog\n\n            Dialog.ask(\"What is your name?\")\n            ```\n\n        Args:\n           message (str): Message to be displayed in the terminal.\n           title (str): Title of the dialog box.\n        \"\"\"\n        if not title:\n            title = \"Input\"\n        if message and title:\n            value = input_dialog(title=title, text=message).run()\n            return value\n        else:\n            print(\"'title' and 'message' are required for prompt_input()\")\n\n    @staticmethod\n    def confirm(message: str = None):\n        \"\"\"\n        Prompt for user input in the terminal.\n\n        Example:\n            ```python\n            Dialog.confirm(\"Are you sure?\")\n            ```\n\n        Args:\n           message (str): Message to be displayed in the terminal.    \n        \"\"\"\n        if not message:\n            message = \"\"\n        if message:\n            value = yes_no_dialog(title=\"Confirmation\", text=message).run()\n            return value\n        else:\n            print(\"'message' is required for prompt_confirmation()\")\n\n    @staticmethod\n    def asklist(choices: list = None, message: str = None):\n        \"\"\"\n        Prompt for user input in the terminal.\n\n        Example:\n            ```python\n            list = [\"Red\", \"Green\", \"Blue\"]\n            Dialog.asklist(\"Choose a color:\", list)\n            ```\n\n        Args:\n           choices (list): A list of options for the user to choose from.\n           message (str): Message to be displayed in the terminal.\n        \"\"\"\n        if not message:\n            message = \"\"\n        if message and choices:\n            value = input_dialog(title=message, text=message, completer=WordCompleter(words=choices)).run()\n            return value\n        else:\n            print(\"'message' and 'choices' are required for asklist()\")\n\n    @staticmethod\n    def radio(choices: str = None, message: str = None):\n        \"\"\"\n        Display a dialog with choices offered as a radio list.\n\n        Example:\n            ```python\n            list = [\"Red\", \"Green\", \"Blue\"]\n            Dialog.radio(\"Choose a color:\", list)\n            ```\n\n        Args:\n           message (str): Message to be displayed in the terminal.\n           choices (list): A list of tuples for the radio options.\n        \"\"\"\n        if not message:\n            message = \"\"\n        if message and choices:\n            value = radiolist_dialog(title=\"RadioList dialog\", text=message, values=choices).run()\n            return value\n        else:\n            print(\"'message' and 'choices' are required for radiolist()\")\n\n    @staticmethod\n    def checkbox(choices: str = None, message: str = None):\n        \"\"\"\n        Display a dialog with choices offered as a checkbox list.\n\n        Example:\n            ```python\n            list = [\"Red\", \"Green\", \"Blue\"]\n            Dialog.checkbox(\"Choose a color:\", list)\n            ```\n\n        Args:\n           message (str): Message to be displayed in the terminal.\n           choices (list): A list of tuples for the checkbox options.\n        \"\"\"\n        if not message:\n            message = \"\"\n        if message and choices:\n            value = checkboxlist_dialog(title=\"CheckboxList dialog\", text=message, values=choices).run()\n            return value\n        else:\n            print(\"'message' and 'choices' are required for checkboxlist()\")\n\n    @staticmethod\n    def button(choices: str = None, message: str = None):\n        \"\"\"\n        Display a dialog with choices offered as buttons.\n\n        Example:\n            ```python\n            list = [\"Red\", \"Green\", \"Blue\"]\n            Dialog.button(\"Choose a color:\", list)\n            ```\n\n        Args:\n           message (str): Message to be displayed in the terminal.\n           choices (list): A list of tuples for the button options.\n        \"\"\"\n        if not message:\n            message = \"\"\n        if message and choices:\n            value = button_dialog(title=\"Button dialog\", text=message, buttons=choices).run()\n            return value\n        else:\n            print(\"'message' and 'choices' are required for button()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.__init__","title":"<code>__init__()</code>","text":"<p>A lighweight for handling user inputs in the terminal.</p> <p>Attributes:</p> Name Type Description <code>ask</code> <p>A method to prompt the user for input in the terminal.</p> <code>confirm</code> <p>A method to prompt the user for a yes/no confirmation.</p> <code>asklist</code> <p>A method to prompt the user to select from a list of choices.</p> <code>radio</code> <p>A method to prompt the user to select from a list of choices using a radio list.</p> <code>checkbox</code> <p>A method to prompt the user to select from a list of choices using a checkbox list.</p> <code>button</code> <p>A method to prompt the user to select from a list of choices using buttons.</p> Source code in <code>yosemite/tools/input.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    A lighweight for handling user inputs in the terminal.\n\n    Attributes:\n        ask: A method to prompt the user for input in the terminal.\n        confirm: A method to prompt the user for a yes/no confirmation.\n        asklist: A method to prompt the user to select from a list of choices.\n        radio: A method to prompt the user to select from a list of choices using a radio list.\n        checkbox: A method to prompt the user to select from a list of choices using a checkbox list.\n        button: A method to prompt the user to select from a list of choices using buttons.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.ask","title":"<code>ask(message=None, title=None)</code>  <code>staticmethod</code>","text":"<p>Prompt for user input in the terminal.</p> Example <pre><code>from yosemite.tools.input import Dialog\n\nDialog.ask(\"What is your name?\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to be displayed in the terminal.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the dialog box.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef ask(message: str = None, title: str = None):\n    \"\"\"\n    Prompt for user input in the terminal.\n\n    Example:\n        ```python\n        from yosemite.tools.input import Dialog\n\n        Dialog.ask(\"What is your name?\")\n        ```\n\n    Args:\n       message (str): Message to be displayed in the terminal.\n       title (str): Title of the dialog box.\n    \"\"\"\n    if not title:\n        title = \"Input\"\n    if message and title:\n        value = input_dialog(title=title, text=message).run()\n        return value\n    else:\n        print(\"'title' and 'message' are required for prompt_input()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.asklist","title":"<code>asklist(choices=None, message=None)</code>  <code>staticmethod</code>","text":"<p>Prompt for user input in the terminal.</p> Example <pre><code>list = [\"Red\", \"Green\", \"Blue\"]\nDialog.asklist(\"Choose a color:\", list)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>choices</code> <code>list</code> <p>A list of options for the user to choose from.</p> <code>None</code> <code>message</code> <code>str</code> <p>Message to be displayed in the terminal.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef asklist(choices: list = None, message: str = None):\n    \"\"\"\n    Prompt for user input in the terminal.\n\n    Example:\n        ```python\n        list = [\"Red\", \"Green\", \"Blue\"]\n        Dialog.asklist(\"Choose a color:\", list)\n        ```\n\n    Args:\n       choices (list): A list of options for the user to choose from.\n       message (str): Message to be displayed in the terminal.\n    \"\"\"\n    if not message:\n        message = \"\"\n    if message and choices:\n        value = input_dialog(title=message, text=message, completer=WordCompleter(words=choices)).run()\n        return value\n    else:\n        print(\"'message' and 'choices' are required for asklist()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.button","title":"<code>button(choices=None, message=None)</code>  <code>staticmethod</code>","text":"<p>Display a dialog with choices offered as buttons.</p> Example <pre><code>list = [\"Red\", \"Green\", \"Blue\"]\nDialog.button(\"Choose a color:\", list)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to be displayed in the terminal.</p> <code>None</code> <code>choices</code> <code>list</code> <p>A list of tuples for the button options.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef button(choices: str = None, message: str = None):\n    \"\"\"\n    Display a dialog with choices offered as buttons.\n\n    Example:\n        ```python\n        list = [\"Red\", \"Green\", \"Blue\"]\n        Dialog.button(\"Choose a color:\", list)\n        ```\n\n    Args:\n       message (str): Message to be displayed in the terminal.\n       choices (list): A list of tuples for the button options.\n    \"\"\"\n    if not message:\n        message = \"\"\n    if message and choices:\n        value = button_dialog(title=\"Button dialog\", text=message, buttons=choices).run()\n        return value\n    else:\n        print(\"'message' and 'choices' are required for button()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.checkbox","title":"<code>checkbox(choices=None, message=None)</code>  <code>staticmethod</code>","text":"<p>Display a dialog with choices offered as a checkbox list.</p> Example <pre><code>list = [\"Red\", \"Green\", \"Blue\"]\nDialog.checkbox(\"Choose a color:\", list)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to be displayed in the terminal.</p> <code>None</code> <code>choices</code> <code>list</code> <p>A list of tuples for the checkbox options.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef checkbox(choices: str = None, message: str = None):\n    \"\"\"\n    Display a dialog with choices offered as a checkbox list.\n\n    Example:\n        ```python\n        list = [\"Red\", \"Green\", \"Blue\"]\n        Dialog.checkbox(\"Choose a color:\", list)\n        ```\n\n    Args:\n       message (str): Message to be displayed in the terminal.\n       choices (list): A list of tuples for the checkbox options.\n    \"\"\"\n    if not message:\n        message = \"\"\n    if message and choices:\n        value = checkboxlist_dialog(title=\"CheckboxList dialog\", text=message, values=choices).run()\n        return value\n    else:\n        print(\"'message' and 'choices' are required for checkboxlist()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.confirm","title":"<code>confirm(message=None)</code>  <code>staticmethod</code>","text":"<p>Prompt for user input in the terminal.</p> Example <pre><code>Dialog.confirm(\"Are you sure?\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to be displayed in the terminal.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef confirm(message: str = None):\n    \"\"\"\n    Prompt for user input in the terminal.\n\n    Example:\n        ```python\n        Dialog.confirm(\"Are you sure?\")\n        ```\n\n    Args:\n       message (str): Message to be displayed in the terminal.    \n    \"\"\"\n    if not message:\n        message = \"\"\n    if message:\n        value = yes_no_dialog(title=\"Confirmation\", text=message).run()\n        return value\n    else:\n        print(\"'message' is required for prompt_confirmation()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Dialog.radio","title":"<code>radio(choices=None, message=None)</code>  <code>staticmethod</code>","text":"<p>Display a dialog with choices offered as a radio list.</p> Example <pre><code>list = [\"Red\", \"Green\", \"Blue\"]\nDialog.radio(\"Choose a color:\", list)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to be displayed in the terminal.</p> <code>None</code> <code>choices</code> <code>list</code> <p>A list of tuples for the radio options.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef radio(choices: str = None, message: str = None):\n    \"\"\"\n    Display a dialog with choices offered as a radio list.\n\n    Example:\n        ```python\n        list = [\"Red\", \"Green\", \"Blue\"]\n        Dialog.radio(\"Choose a color:\", list)\n        ```\n\n    Args:\n       message (str): Message to be displayed in the terminal.\n       choices (list): A list of tuples for the radio options.\n    \"\"\"\n    if not message:\n        message = \"\"\n    if message and choices:\n        value = radiolist_dialog(title=\"RadioList dialog\", text=message, values=choices).run()\n        return value\n    else:\n        print(\"'message' and 'choices' are required for radiolist()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Input","title":"<code>Input</code>","text":"Source code in <code>yosemite/tools/input.py</code> <pre><code>class Input:\n    def __init__(self):\n        \"\"\"\n        A lighweight for handling user inputs in the terminal.\n        Uses Prompt Toolkit for both simple CLI text and expressive GUI dialogs.\n\n        Attributes:\n            pause: A method to pause the terminal until the user presses Enter.\n            confirm: A method to prompt the user for a yes/no confirmation.\n            ask: A method to prompt the user for input in the terminal.\n            choice: A method to prompt the user to select from a list of choices.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def pause(message: str = None):\n        \"\"\"\n        Pauses the terminal until the user presses Enter.\n\n        Example:\n            ```python\n            from yosemite.tools.input import Input\n\n            Input.pause()\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n            \"\"\"\n        if not message:\n            message = \"\"\"\nPress Enter to continue...\n\n\"\"\"\n\n    @staticmethod\n    def confirm(message: str = None):\n        \"\"\"\n        Prompt the user for a yes/no confirmation.\n\n        Example:\n            ```python\n            Input.confirm(\"Are you sure?\")\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n        \"\"\"\n        if not message:\n            message = \"\"\n        if message:\n            value = yes_no_dialog(title=\"Confirmation\", text=message).run()\n            return value\n        else:\n            print(\"'message' is required for prompt_confirmation()\")\n\n    @staticmethod\n    def ask(message: str = None):\n        \"\"\"\n        Prompt the user for input in the terminal.\n\n        Example:\n            ```python\n            name = Input.ask(\"What is your name?\")\n            print(f\"Hello, {name}!\")\n            ```\n\n            ```bash\n            Hello, John!\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n        \"\"\"\n        if not message:\n            message = \"\"\"\n\"\"\"     \n        if message:\n            message = f\"\"\"\n{message}\n\n\"\"\"\n        if message:\n            value = prompt(message)\n            return value\n        else:\n            print(\"'message' is required for prompt_input()\")\n\n    @staticmethod\n    def choice(message: str = None, choices: list = None):\n        \"\"\"\n        Prompt the user to select from a list of choices.\n\n        Example:\n            ```python\n            list = [\"Red\", \"Green\", \"Blue\"]\n            color = Input.choice(\"Choose a color:\", list)\n            print(f\"You chose {color}.\")\n            ```\n\n            ```bash\n            You chose Red.\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n            choices (list): A list of choices for the user to select from.\n        \"\"\"\n        if not message:\n            message = \"\"\"\n\"\"\"\n        if message:\n            message = f\"\"\"\n{message}\n\n\"\"\"\n        if message and choices:\n            value = prompt(message=message, completer=WordCompleter(words=choices))\n            return value\n        else:\n            print(\"'message' and 'choices' are required for prompt_choice()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Input.__init__","title":"<code>__init__()</code>","text":"<p>A lighweight for handling user inputs in the terminal. Uses Prompt Toolkit for both simple CLI text and expressive GUI dialogs.</p> <p>Attributes:</p> Name Type Description <code>pause</code> <p>A method to pause the terminal until the user presses Enter.</p> <code>confirm</code> <p>A method to prompt the user for a yes/no confirmation.</p> <code>ask</code> <p>A method to prompt the user for input in the terminal.</p> <code>choice</code> <p>A method to prompt the user to select from a list of choices.</p> Source code in <code>yosemite/tools/input.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    A lighweight for handling user inputs in the terminal.\n    Uses Prompt Toolkit for both simple CLI text and expressive GUI dialogs.\n\n    Attributes:\n        pause: A method to pause the terminal until the user presses Enter.\n        confirm: A method to prompt the user for a yes/no confirmation.\n        ask: A method to prompt the user for input in the terminal.\n        choice: A method to prompt the user to select from a list of choices.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Input.ask","title":"<code>ask(message=None)</code>  <code>staticmethod</code>","text":"<p>Prompt the user for input in the terminal.</p> Example <pre><code>name = Input.ask(\"What is your name?\")\nprint(f\"Hello, {name}!\")\n</code></pre> <pre><code>Hello, John!\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display to the user.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>    @staticmethod\n    def ask(message: str = None):\n        \"\"\"\n        Prompt the user for input in the terminal.\n\n        Example:\n            ```python\n            name = Input.ask(\"What is your name?\")\n            print(f\"Hello, {name}!\")\n            ```\n\n            ```bash\n            Hello, John!\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n        \"\"\"\n        if not message:\n            message = \"\"\"\n\"\"\"     \n        if message:\n            message = f\"\"\"\n{message}\n\n\"\"\"\n        if message:\n            value = prompt(message)\n            return value\n        else:\n            print(\"'message' is required for prompt_input()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Input.choice","title":"<code>choice(message=None, choices=None)</code>  <code>staticmethod</code>","text":"<p>Prompt the user to select from a list of choices.</p> Example <pre><code>list = [\"Red\", \"Green\", \"Blue\"]\ncolor = Input.choice(\"Choose a color:\", list)\nprint(f\"You chose {color}.\")\n</code></pre> <pre><code>You chose Red.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display to the user.</p> <code>None</code> <code>choices</code> <code>list</code> <p>A list of choices for the user to select from.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>    @staticmethod\n    def choice(message: str = None, choices: list = None):\n        \"\"\"\n        Prompt the user to select from a list of choices.\n\n        Example:\n            ```python\n            list = [\"Red\", \"Green\", \"Blue\"]\n            color = Input.choice(\"Choose a color:\", list)\n            print(f\"You chose {color}.\")\n            ```\n\n            ```bash\n            You chose Red.\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n            choices (list): A list of choices for the user to select from.\n        \"\"\"\n        if not message:\n            message = \"\"\"\n\"\"\"\n        if message:\n            message = f\"\"\"\n{message}\n\n\"\"\"\n        if message and choices:\n            value = prompt(message=message, completer=WordCompleter(words=choices))\n            return value\n        else:\n            print(\"'message' and 'choices' are required for prompt_choice()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Input.confirm","title":"<code>confirm(message=None)</code>  <code>staticmethod</code>","text":"<p>Prompt the user for a yes/no confirmation.</p> Example <pre><code>Input.confirm(\"Are you sure?\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display to the user.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>@staticmethod\ndef confirm(message: str = None):\n    \"\"\"\n    Prompt the user for a yes/no confirmation.\n\n    Example:\n        ```python\n        Input.confirm(\"Are you sure?\")\n        ```\n\n    Args:\n        message (str): The message to display to the user.\n    \"\"\"\n    if not message:\n        message = \"\"\n    if message:\n        value = yes_no_dialog(title=\"Confirmation\", text=message).run()\n        return value\n    else:\n        print(\"'message' is required for prompt_confirmation()\")\n</code></pre>"},{"location":"api/tools/yosemite.tools.input/#yosemite.tools.input.Input.pause","title":"<code>pause(message=None)</code>  <code>staticmethod</code>","text":"<p>Pauses the terminal until the user presses Enter.</p> Example <pre><code>from yosemite.tools.input import Input\n\nInput.pause()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display to the user.</p> <code>None</code> Source code in <code>yosemite/tools/input.py</code> <pre><code>    @staticmethod\n    def pause(message: str = None):\n        \"\"\"\n        Pauses the terminal until the user presses Enter.\n\n        Example:\n            ```python\n            from yosemite.tools.input import Input\n\n            Input.pause()\n            ```\n\n        Args:\n            message (str): The message to display to the user.\n            \"\"\"\n        if not message:\n            message = \"\"\"\nPress Enter to continue...\n\n\"\"\"\n</code></pre>"},{"location":"api/tools/yosemite.tools.load/","title":"Animated Loaders (Depreciated)","text":"<pre><code>from yosemite.tools import Status, Timer\n\nstatus = Status()\n\nwith status(\"Loading...\"):\n    # Your Function Here\n</code></pre>"},{"location":"api/tools/yosemite.tools.load/#yosemite.tools.load.Loader","title":"<code>Loader</code>","text":"<p>Displays a simple animated loading placeholder. Now depreciated. Use 'alive-progress' instead.</p> <pre><code>pip install alive-progress\n</code></pre> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>The message to be displayed while loading.</p> <code>color</code> <code>str</code> <p>The color of the loading animation.</p> <code>animation</code> <code>str</code> <p>The animation to be displayed while loading.</p> <code>styles</code> <code>str</code> <p>The style of the animation to be displayed while loading.</p> Source code in <code>yosemite/tools/load.py</code> <pre><code>class Loader:\n    \"\"\"Displays a simple animated loading placeholder. Now depreciated. Use 'alive-progress' instead.\n\n    ```bash\n    pip install alive-progress\n    ```\n\n    Attributes:\n        message (str): The message to be displayed while loading.\n        color (str): The color of the loading animation.\n        animation (str): The animation to be displayed while loading.\n        styles (str): The style of the animation to be displayed while loading.\n    \"\"\"\n\n    def __init__(self, message: str = \"Loading...\", color: str = \"white\", animation: str = \"|/-\\\\\", styles: str = None):\n        \"\"\"\n        Generates a simple animated loading placeholder.\n\n        Example:\n            ```python\n            from yosemite.tools.load import Loader\n\n            loader = Loader()\n            with loader:\n                time.sleep(2)\n                loader.checkpoint(\"Checkpoint 1\")\n                time.sleep(2)\n            ```\n\n        Args:\n            message (str, optional): The message to be displayed while loading. Defaults to \"Loading...\".\n            color (str, optional): The color of the loading animation. Defaults to \"white\".\n            animation (str, optional): The animation to be displayed while loading. Defaults to \"|/-\\\\\".\n            styles (str, optional): The style of the animation to be displayed while loading. Defaults to None.\n        \"\"\"\n        self.say = Text()\n        self.timer = Timer()\n        self.message = message\n        self.color = color\n        self.animation = animation\n        self.is_running = False\n        self.index = 0\n\n        self.say.say(\"The yosemite.core.modules.loaders module will no longer be updated. I have personally started using the 'alive-progress' module for this purpose.\", color=\"yellow\")\n        self.say.say(\"You can install it using 'pip install alive-progress'.\", color=\"yellow\", bold=True)\n\n        animations = {\n            \"blocks\": \"\u2588\u2589\u258a\u258b\u258c\u258d\u258e\u258f \",\n            \"emoji\": \"\ud83c\udf11\ud83c\udf12\ud83c\udf13\ud83c\udf14\ud83c\udf15\ud83c\udf16\ud83c\udf17\ud83c\udf18\",\n            \"hourglass\": \"\u23f3\u231b\",\n            \"dots\": \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\",\n            \"arrows\": \"\u2190\u2196\u2191\u2197\u2192\u2198\u2193\u2199\",\n            \"lines\": \"\u2524\u2518\u2534\u2514\u251c\u250c\u252c\u2510\",\n            \"pipes\": \"\u2503\u2503\u2503\u2503\u2503\u2503\u2503\u2503\u2503\",\n            \"dots2\": \"\u28fe\u28fd\u28fb\u28bf\u287f\u28df\u28ef\u28f7\",\n            \"dots3\": \"\u2884\u2882\u2881\u2841\u2848\u2850\u2860\",\n            \"stars\": \"\u2736\u2738\u2739\u273a\u2739\u2737\",\n            \"ping\": \"\u26ab\u26aa\",\n            \"hearts\": \"\ud83d\udc97\ud83d\udc93\ud83d\udc95\ud83d\udc96\ud83d\udc9e\ud83d\udc98\ud83d\udc9d\ud83d\udc9f\",\n            \"weather\": \"\ud83c\udf24\ufe0f\ud83c\udf25\ufe0f\ud83c\udf26\ufe0f\ud83c\udf27\ufe0f\u26c8\ufe0f\ud83c\udf29\ufe0f\ud83c\udf28\ufe0f\u2603\ufe0f\",\n            \"moons\": \"\ud83c\udf11\ud83c\udf12\ud83c\udf13\ud83c\udf14\ud83c\udf15\ud83c\udf16\ud83c\udf17\ud83c\udf18\ud83c\udf11\"\n        }\n\n        if styles in animations:\n            self.animation = animations[styles]\n\n    def __enter__(self):\n        self.timer.enter()\n        self.is_running = True\n        self.thread = threading.Thread(target=self._animate)\n        self.thread.start()\n        return self\n\n    def _animate(self):\n        while self.is_running:\n            sys.stdout.write(f\"\\r{self.message} {self.animation[self.index]}\")\n            sys.stdout.flush()\n            time.sleep(0.1)\n            self.index = (self.index + 1) % len(self.animation)\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.is_running = False\n        self.thread.join()\n        sys.stdout.write(\"\\r\" + \" \" * (len(self.message) + 2) + \"\\n\")\n        self.timer.exit()\n\n    def checkpoint(self, message: str):\n        \"\"\"Displays a checkpoint message while the loader is running.\n\n        Example:\n            ```python\n            loader = Loader()\n            with loader:\n                time.sleep(2)\n                loader.checkpoint(\"Checkpoint 1\")\n                time.sleep(2)\n            ```\n\n        Args:\n            message (str): The checkpoint message to be displayed.\n        \"\"\"\n        self.is_running = False\n        self.thread.join()\n        checkpoint_message = f\"\\r{self.message} {message}\\n\"\n        sys.stdout.write(checkpoint_message)\n        sys.stdout.flush()\n        time.sleep(1)\n        self.is_running = True\n        self.thread = threading.Thread(target=self._animate)\n        self.thread.start()\n</code></pre>"},{"location":"api/tools/yosemite.tools.load/#yosemite.tools.load.Loader.__init__","title":"<code>__init__(message='Loading...', color='white', animation='|/-\\\\', styles=None)</code>","text":"<p>Generates a simple animated loading placeholder.</p> Example <pre><code>from yosemite.tools.load import Loader\n\nloader = Loader()\nwith loader:\n    time.sleep(2)\n    loader.checkpoint(\"Checkpoint 1\")\n    time.sleep(2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to be displayed while loading. Defaults to \"Loading...\".</p> <code>'Loading...'</code> <code>color</code> <code>str</code> <p>The color of the loading animation. Defaults to \"white\".</p> <code>'white'</code> <code>animation</code> <code>str</code> <p>The animation to be displayed while loading. Defaults to \"|/-\\\".</p> <code>'|/-\\\\'</code> <code>styles</code> <code>str</code> <p>The style of the animation to be displayed while loading. Defaults to None.</p> <code>None</code> Source code in <code>yosemite/tools/load.py</code> <pre><code>def __init__(self, message: str = \"Loading...\", color: str = \"white\", animation: str = \"|/-\\\\\", styles: str = None):\n    \"\"\"\n    Generates a simple animated loading placeholder.\n\n    Example:\n        ```python\n        from yosemite.tools.load import Loader\n\n        loader = Loader()\n        with loader:\n            time.sleep(2)\n            loader.checkpoint(\"Checkpoint 1\")\n            time.sleep(2)\n        ```\n\n    Args:\n        message (str, optional): The message to be displayed while loading. Defaults to \"Loading...\".\n        color (str, optional): The color of the loading animation. Defaults to \"white\".\n        animation (str, optional): The animation to be displayed while loading. Defaults to \"|/-\\\\\".\n        styles (str, optional): The style of the animation to be displayed while loading. Defaults to None.\n    \"\"\"\n    self.say = Text()\n    self.timer = Timer()\n    self.message = message\n    self.color = color\n    self.animation = animation\n    self.is_running = False\n    self.index = 0\n\n    self.say.say(\"The yosemite.core.modules.loaders module will no longer be updated. I have personally started using the 'alive-progress' module for this purpose.\", color=\"yellow\")\n    self.say.say(\"You can install it using 'pip install alive-progress'.\", color=\"yellow\", bold=True)\n\n    animations = {\n        \"blocks\": \"\u2588\u2589\u258a\u258b\u258c\u258d\u258e\u258f \",\n        \"emoji\": \"\ud83c\udf11\ud83c\udf12\ud83c\udf13\ud83c\udf14\ud83c\udf15\ud83c\udf16\ud83c\udf17\ud83c\udf18\",\n        \"hourglass\": \"\u23f3\u231b\",\n        \"dots\": \"\u280b\u2819\u2839\u2838\u283c\u2834\u2826\u2827\u2807\u280f\",\n        \"arrows\": \"\u2190\u2196\u2191\u2197\u2192\u2198\u2193\u2199\",\n        \"lines\": \"\u2524\u2518\u2534\u2514\u251c\u250c\u252c\u2510\",\n        \"pipes\": \"\u2503\u2503\u2503\u2503\u2503\u2503\u2503\u2503\u2503\",\n        \"dots2\": \"\u28fe\u28fd\u28fb\u28bf\u287f\u28df\u28ef\u28f7\",\n        \"dots3\": \"\u2884\u2882\u2881\u2841\u2848\u2850\u2860\",\n        \"stars\": \"\u2736\u2738\u2739\u273a\u2739\u2737\",\n        \"ping\": \"\u26ab\u26aa\",\n        \"hearts\": \"\ud83d\udc97\ud83d\udc93\ud83d\udc95\ud83d\udc96\ud83d\udc9e\ud83d\udc98\ud83d\udc9d\ud83d\udc9f\",\n        \"weather\": \"\ud83c\udf24\ufe0f\ud83c\udf25\ufe0f\ud83c\udf26\ufe0f\ud83c\udf27\ufe0f\u26c8\ufe0f\ud83c\udf29\ufe0f\ud83c\udf28\ufe0f\u2603\ufe0f\",\n        \"moons\": \"\ud83c\udf11\ud83c\udf12\ud83c\udf13\ud83c\udf14\ud83c\udf15\ud83c\udf16\ud83c\udf17\ud83c\udf18\ud83c\udf11\"\n    }\n\n    if styles in animations:\n        self.animation = animations[styles]\n</code></pre>"},{"location":"api/tools/yosemite.tools.load/#yosemite.tools.load.Loader.checkpoint","title":"<code>checkpoint(message)</code>","text":"<p>Displays a checkpoint message while the loader is running.</p> Example <pre><code>loader = Loader()\nwith loader:\n    time.sleep(2)\n    loader.checkpoint(\"Checkpoint 1\")\n    time.sleep(2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The checkpoint message to be displayed.</p> required Source code in <code>yosemite/tools/load.py</code> <pre><code>def checkpoint(self, message: str):\n    \"\"\"Displays a checkpoint message while the loader is running.\n\n    Example:\n        ```python\n        loader = Loader()\n        with loader:\n            time.sleep(2)\n            loader.checkpoint(\"Checkpoint 1\")\n            time.sleep(2)\n        ```\n\n    Args:\n        message (str): The checkpoint message to be displayed.\n    \"\"\"\n    self.is_running = False\n    self.thread.join()\n    checkpoint_message = f\"\\r{self.message} {message}\\n\"\n    sys.stdout.write(checkpoint_message)\n    sys.stdout.flush()\n    time.sleep(1)\n    self.is_running = True\n    self.thread = threading.Thread(target=self._animate)\n    self.thread.start()\n</code></pre>"},{"location":"api/tools/yosemite.tools.load/#yosemite.tools.load.Timer","title":"<code>Timer</code>","text":"<p>Measures and prints the execution time of a task.</p> Example <pre><code>from yosemite.tools.load import Timer\n\ntimer = Timer()\nwith timer.enter():\n    time.sleep(2)\n</code></pre> <pre><code>Task completed in 2.00 seconds.\n</code></pre> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>The message to be displayed while timing.</p> Source code in <code>yosemite/tools/load.py</code> <pre><code>class Timer:\n    \"\"\"Measures and prints the execution time of a task.\n\n    Example:\n        ```python\n        from yosemite.tools.load import Timer\n\n        timer = Timer()\n        with timer.enter():\n            time.sleep(2)\n        ```\n\n        ```bash\n        Task completed in 2.00 seconds.\n        ```\n\n    Attributes:\n        message (str): The message to be displayed while timing.\n        \"\"\"\n\n    def __init__(self, message: str = \"Task\"):\n        self.say = Text()\n        self.message = message\n\n    def enter(self):\n        self.start_time = time.time()\n        return self\n\n    def exit(self):\n        end_time = time.time()\n        elapsed_time = end_time - self.start_time\n        message = f\"{self.message} completed in {elapsed_time:.2f} seconds.\"\n        self.say.say(message, color=\"green\", bold=True)\n</code></pre>"},{"location":"api/tools/yosemite.tools.text/","title":"CLI Text Styling","text":"<pre><code>from yosemite.tools import Text\n\ntext = Text()\ntext.say(\"Hello World!\", color=\"green\", bg=\"rgb(32, 133, 122)\", bold=True, italic=True, underline=True)\n</code></pre>"},{"location":"api/tools/yosemite.tools.text/#yosemite.tools.text.Text","title":"<code>Text</code>","text":"<p>Dynamic, interchangable text styling for the terminal. Compatible with RGB, background colors, bold, italic, and underline text.</p> <p>Attributes:</p> Name Type Description <code>say</code> <p>A method to style and print a single line of text.</p> <code>list</code> <p>A method to style and print a list of items.</p> <code>splash</code> <p>A method to create an ASCII art styled Splash 'Logo' in the terminal.</p> Source code in <code>yosemite/tools/text.py</code> <pre><code>class Text:\n    \"\"\"\n    Dynamic, interchangable text styling for the terminal. Compatible with RGB, background colors, bold, italic, and underline text.\n\n    Attributes:\n        say: A method to style and print a single line of text.\n        list: A method to style and print a list of items.\n        splash: A method to create an ASCII art styled Splash 'Logo' in the terminal.\n    \"\"\"\n    def say(self, message, color=\"white\", bg=None, bold=False, italic=False, underline=False):\n        \"\"\"\n        Style and print a single line of text.\n\n        Example:\n            ```python\n            from yosemite.tools.text import Text\n\n            text = Text()\n            text.say(\"Hello, World!\", color=\"red\", bg=\"white\", bold=True)\n            ```\n\n            ```bash\n            Hello, World!\n            ```\n\n        Args:\n            message (str): The message to be styled and printed.\n            color (str, optional): The color of the text. Defaults to \"white\".\n            bg (str, optional): The background color of the text. Defaults to None.\n            bold (bool, optional): Whether the text should be bold. Defaults to False.\n            italic (bool, optional): Whether the text should be italic. Defaults to False.\n            underline (bool, optional): Whether the text should be underlined. Defaults to False.\n        \"\"\"\n        styled_message = libhammadpy_text.format_text(message, color, bg, bold, italic, underline)\n        print(styled_message)\n\n    def list(self, items, color=\"white\", bg=None, bold=False, italic=False, underline=False):\n        \"\"\"\n        Style and print a list of items.\n\n        Example:\n            ```python\n            from yosemite.tools.text import Text\n\n            text = Text()\n            text.list([\"apple\", \"banana\", \"cherry\"], color=\"green\", bg=\"black\", bold=True)\n            ```\n\n            ```bash\n            apple\n            banana\n            cherry\n            ```\n\n        Args:\n            items (list): The items to be styled and printed.\n            color (str, optional): The color of the text. Defaults to \"white\".\n            bg (str, optional): The background color of the text. Defaults to None.\n            bold (bool, optional): Whether the text should be bold. Defaults to False.\n            italic (bool, optional): Whether the text should be italic. Defaults to False.\n            underline (bool, optional): Whether the text should be underlined. Defaults to False.\n        \"\"\"\n        styled_items = libhammadpy_text.format_list(items, color, bg, bold, italic, underline)\n        for item in styled_items:\n            print(item)\n\n    def splash(self, message: str = \"hammadpy\", art: str = \"random\", color: str = \"white\", bg: str = None, bold: bool = False, italic: bool = False, underline: bool = False):\n        \"\"\"\n        Creates an ASCII art styled Splash 'Logo' in the terminal.\n\n        Example:\n            ```python\n            from yosemite.tools.text import Text\n\n            text = Text()\n            text.splash(\"hammadpy\", art=\"random\", color=\"white\", bg=\"black\", bold=True)\n            ```\n\n        Args:\n            message (str): The message to display in the splash.\n            art (str): The ASCII art style to use.\n            color (str): Text color (e.g., 'red', 'blue').\n            bg (str): Background color (e.g., 'red', 'blue').\n            bold (bool): Whether the text should be bold.\n            italic (bool): Whether the text should be italic.\n            underline (bool): Whether the text should be underlined.\n        \"\"\"\n        if art == \"random\":\n            fonts = [\"block\", \"caligraphy\", \"doh\", \"dohc\", \"doom\", \"epic\", \"fender\", \"graffiti\", \"isometric1\", \"isometric2\", \"isometric3\", \"isometric4\", \"letters\", \"alligator\", \"dotmatrix\", \"bubble\", \"bulbhead\", \"digital\", \"ivrit\", \"lean\", \"mini\", \"script\", \"shadow\", \"slant\", \"speed\", \"starwars\", \"stop\", \"thin\", \"3-d\", \"3x5\", \"5lineoblique\", \"acrobatic\", \"alligator2\", \"alligator3\", \"alphabet\", \"banner\", \"banner3-D\", \"banner3\", \"banner4\", \"barbwire\", \"basic\", \"bell\", \"big\", \"bigchief\", \"binary\", \"block\", \"broadway\", \"bubble\", \"caligraphy\", \"doh\", \"dohc\", \"doom\", \"dotmatrix\", \"drpepper\", \"epic\", \"fender\", \"graffiti\", \"isometric1\", \"isometric2\", \"isometric3\", \"isometric4\", \"letters\", \"alligator\", \"dotmatrix\", \"bubble\", \"bulbhead\", \"digital\", \"ivrit\", \"lean\", \"mini\", \"script\", \"shadow\", \"slant\", \"speed\", \"starwars\", \"stop\", \"thin\"]\n            art = random.choice(fonts)\n\n        art_message = text2art(message, font=art)\n        self.say(art_message, color=color, bg=bg, bold=bold, italic=italic, underline=underline)\n</code></pre>"},{"location":"api/tools/yosemite.tools.text/#yosemite.tools.text.Text.list","title":"<code>list(items, color='white', bg=None, bold=False, italic=False, underline=False)</code>","text":"<p>Style and print a list of items.</p> Example <pre><code>from yosemite.tools.text import Text\n\ntext = Text()\ntext.list([\"apple\", \"banana\", \"cherry\"], color=\"green\", bg=\"black\", bold=True)\n</code></pre> <pre><code>apple\nbanana\ncherry\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list</code> <p>The items to be styled and printed.</p> required <code>color</code> <code>str</code> <p>The color of the text. Defaults to \"white\".</p> <code>'white'</code> <code>bg</code> <code>str</code> <p>The background color of the text. Defaults to None.</p> <code>None</code> <code>bold</code> <code>bool</code> <p>Whether the text should be bold. Defaults to False.</p> <code>False</code> <code>italic</code> <code>bool</code> <p>Whether the text should be italic. Defaults to False.</p> <code>False</code> <code>underline</code> <code>bool</code> <p>Whether the text should be underlined. Defaults to False.</p> <code>False</code> Source code in <code>yosemite/tools/text.py</code> <pre><code>def list(self, items, color=\"white\", bg=None, bold=False, italic=False, underline=False):\n    \"\"\"\n    Style and print a list of items.\n\n    Example:\n        ```python\n        from yosemite.tools.text import Text\n\n        text = Text()\n        text.list([\"apple\", \"banana\", \"cherry\"], color=\"green\", bg=\"black\", bold=True)\n        ```\n\n        ```bash\n        apple\n        banana\n        cherry\n        ```\n\n    Args:\n        items (list): The items to be styled and printed.\n        color (str, optional): The color of the text. Defaults to \"white\".\n        bg (str, optional): The background color of the text. Defaults to None.\n        bold (bool, optional): Whether the text should be bold. Defaults to False.\n        italic (bool, optional): Whether the text should be italic. Defaults to False.\n        underline (bool, optional): Whether the text should be underlined. Defaults to False.\n    \"\"\"\n    styled_items = libhammadpy_text.format_list(items, color, bg, bold, italic, underline)\n    for item in styled_items:\n        print(item)\n</code></pre>"},{"location":"api/tools/yosemite.tools.text/#yosemite.tools.text.Text.say","title":"<code>say(message, color='white', bg=None, bold=False, italic=False, underline=False)</code>","text":"<p>Style and print a single line of text.</p> Example <pre><code>from yosemite.tools.text import Text\n\ntext = Text()\ntext.say(\"Hello, World!\", color=\"red\", bg=\"white\", bold=True)\n</code></pre> <pre><code>Hello, World!\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to be styled and printed.</p> required <code>color</code> <code>str</code> <p>The color of the text. Defaults to \"white\".</p> <code>'white'</code> <code>bg</code> <code>str</code> <p>The background color of the text. Defaults to None.</p> <code>None</code> <code>bold</code> <code>bool</code> <p>Whether the text should be bold. Defaults to False.</p> <code>False</code> <code>italic</code> <code>bool</code> <p>Whether the text should be italic. Defaults to False.</p> <code>False</code> <code>underline</code> <code>bool</code> <p>Whether the text should be underlined. Defaults to False.</p> <code>False</code> Source code in <code>yosemite/tools/text.py</code> <pre><code>def say(self, message, color=\"white\", bg=None, bold=False, italic=False, underline=False):\n    \"\"\"\n    Style and print a single line of text.\n\n    Example:\n        ```python\n        from yosemite.tools.text import Text\n\n        text = Text()\n        text.say(\"Hello, World!\", color=\"red\", bg=\"white\", bold=True)\n        ```\n\n        ```bash\n        Hello, World!\n        ```\n\n    Args:\n        message (str): The message to be styled and printed.\n        color (str, optional): The color of the text. Defaults to \"white\".\n        bg (str, optional): The background color of the text. Defaults to None.\n        bold (bool, optional): Whether the text should be bold. Defaults to False.\n        italic (bool, optional): Whether the text should be italic. Defaults to False.\n        underline (bool, optional): Whether the text should be underlined. Defaults to False.\n    \"\"\"\n    styled_message = libhammadpy_text.format_text(message, color, bg, bold, italic, underline)\n    print(styled_message)\n</code></pre>"},{"location":"api/tools/yosemite.tools.text/#yosemite.tools.text.Text.splash","title":"<code>splash(message='hammadpy', art='random', color='white', bg=None, bold=False, italic=False, underline=False)</code>","text":"<p>Creates an ASCII art styled Splash 'Logo' in the terminal.</p> Example <pre><code>from yosemite.tools.text import Text\n\ntext = Text()\ntext.splash(\"hammadpy\", art=\"random\", color=\"white\", bg=\"black\", bold=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display in the splash.</p> <code>'hammadpy'</code> <code>art</code> <code>str</code> <p>The ASCII art style to use.</p> <code>'random'</code> <code>color</code> <code>str</code> <p>Text color (e.g., 'red', 'blue').</p> <code>'white'</code> <code>bg</code> <code>str</code> <p>Background color (e.g., 'red', 'blue').</p> <code>None</code> <code>bold</code> <code>bool</code> <p>Whether the text should be bold.</p> <code>False</code> <code>italic</code> <code>bool</code> <p>Whether the text should be italic.</p> <code>False</code> <code>underline</code> <code>bool</code> <p>Whether the text should be underlined.</p> <code>False</code> Source code in <code>yosemite/tools/text.py</code> <pre><code>def splash(self, message: str = \"hammadpy\", art: str = \"random\", color: str = \"white\", bg: str = None, bold: bool = False, italic: bool = False, underline: bool = False):\n    \"\"\"\n    Creates an ASCII art styled Splash 'Logo' in the terminal.\n\n    Example:\n        ```python\n        from yosemite.tools.text import Text\n\n        text = Text()\n        text.splash(\"hammadpy\", art=\"random\", color=\"white\", bg=\"black\", bold=True)\n        ```\n\n    Args:\n        message (str): The message to display in the splash.\n        art (str): The ASCII art style to use.\n        color (str): Text color (e.g., 'red', 'blue').\n        bg (str): Background color (e.g., 'red', 'blue').\n        bold (bool): Whether the text should be bold.\n        italic (bool): Whether the text should be italic.\n        underline (bool): Whether the text should be underlined.\n    \"\"\"\n    if art == \"random\":\n        fonts = [\"block\", \"caligraphy\", \"doh\", \"dohc\", \"doom\", \"epic\", \"fender\", \"graffiti\", \"isometric1\", \"isometric2\", \"isometric3\", \"isometric4\", \"letters\", \"alligator\", \"dotmatrix\", \"bubble\", \"bulbhead\", \"digital\", \"ivrit\", \"lean\", \"mini\", \"script\", \"shadow\", \"slant\", \"speed\", \"starwars\", \"stop\", \"thin\", \"3-d\", \"3x5\", \"5lineoblique\", \"acrobatic\", \"alligator2\", \"alligator3\", \"alphabet\", \"banner\", \"banner3-D\", \"banner3\", \"banner4\", \"barbwire\", \"basic\", \"bell\", \"big\", \"bigchief\", \"binary\", \"block\", \"broadway\", \"bubble\", \"caligraphy\", \"doh\", \"dohc\", \"doom\", \"dotmatrix\", \"drpepper\", \"epic\", \"fender\", \"graffiti\", \"isometric1\", \"isometric2\", \"isometric3\", \"isometric4\", \"letters\", \"alligator\", \"dotmatrix\", \"bubble\", \"bulbhead\", \"digital\", \"ivrit\", \"lean\", \"mini\", \"script\", \"shadow\", \"slant\", \"speed\", \"starwars\", \"stop\", \"thin\"]\n        art = random.choice(fonts)\n\n    art_message = text2art(message, font=art)\n    self.say(art_message, color=color, bg=bg, bold=bold, italic=italic, underline=underline)\n</code></pre>"}]}